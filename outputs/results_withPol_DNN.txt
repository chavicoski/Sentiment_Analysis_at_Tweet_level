
Results of vectorizer CountVectorizer using a SVM with kernel type linear:
acc   = 0.5474308300395256
macro = (0.3825482435155786, 0.3919597337026106, 0.37797007828376794, None)

Results of vectorizer CountVectorizer using a SVM with kernel type poly:
acc   = 0.44466403162055335
macro = (0.3041023921305611, 0.26007639620653317, 0.1734467580836296, None)

Results of vectorizer CountVectorizer using a SVM with kernel type rbf:
acc   = 0.4743083003952569
macro = (0.3341746794871795, 0.2845758693361433, 0.21840855853731395, None)

Results of vectorizer CountVectorizer using a SVM with kernel type sigmoid:
acc   = 0.5434782608695652
macro = (0.29507575757575755, 0.34804179838426413, 0.3025123785072437, None)
Train on 1008 samples, validate on 506 samples
Epoch 1/200
  64/1008 [>.............................] - ETA: 10s - loss: 1.4143 - accuracy: 0.2812
Epoch 00001: val_loss improved from inf to 1.38404, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 1s 896us/sample - loss: 1.4253 - accuracy: 0.2569 - val_loss: 1.3840 - val_accuracy: 0.2945
Epoch 2/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4177 - accuracy: 0.2344
Epoch 00002: val_loss improved from 1.38404 to 1.37833, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 86us/sample - loss: 1.4063 - accuracy: 0.2837 - val_loss: 1.3783 - val_accuracy: 0.3083
Epoch 3/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3852 - accuracy: 0.3125
Epoch 00003: val_loss improved from 1.37833 to 1.37390, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3911 - accuracy: 0.2996 - val_loss: 1.3739 - val_accuracy: 0.3083
Epoch 4/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4169 - accuracy: 0.1875
Epoch 00004: val_loss improved from 1.37390 to 1.36965, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3982 - accuracy: 0.2897 - val_loss: 1.3696 - val_accuracy: 0.3083
Epoch 5/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4067 - accuracy: 0.3281
Epoch 00005: val_loss improved from 1.36965 to 1.36538, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3926 - accuracy: 0.2897 - val_loss: 1.3654 - val_accuracy: 0.3083
Epoch 6/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3902 - accuracy: 0.2812
Epoch 00006: val_loss improved from 1.36538 to 1.36149, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3762 - accuracy: 0.3204 - val_loss: 1.3615 - val_accuracy: 0.3083
Epoch 7/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3793 - accuracy: 0.3125
Epoch 00007: val_loss improved from 1.36149 to 1.35835, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3706 - accuracy: 0.3145 - val_loss: 1.3583 - val_accuracy: 0.3083
Epoch 8/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3463 - accuracy: 0.3594
Epoch 00008: val_loss improved from 1.35835 to 1.35457, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3609 - accuracy: 0.3373 - val_loss: 1.3546 - val_accuracy: 0.3083
Epoch 9/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3706 - accuracy: 0.3125
Epoch 00009: val_loss improved from 1.35457 to 1.35007, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3528 - accuracy: 0.3373 - val_loss: 1.3501 - val_accuracy: 0.3123
Epoch 10/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3352 - accuracy: 0.3906
Epoch 00010: val_loss improved from 1.35007 to 1.34449, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3441 - accuracy: 0.3681 - val_loss: 1.3445 - val_accuracy: 0.3202
Epoch 11/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2850 - accuracy: 0.4219
Epoch 00011: val_loss improved from 1.34449 to 1.34090, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3431 - accuracy: 0.3363 - val_loss: 1.3409 - val_accuracy: 0.3281
Epoch 12/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3635 - accuracy: 0.3281
Epoch 00012: val_loss improved from 1.34090 to 1.33637, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3376 - accuracy: 0.3621 - val_loss: 1.3364 - val_accuracy: 0.3379
Epoch 13/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3474 - accuracy: 0.3594
Epoch 00013: val_loss improved from 1.33637 to 1.33299, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3250 - accuracy: 0.3839 - val_loss: 1.3330 - val_accuracy: 0.3498
Epoch 14/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3297 - accuracy: 0.4062
Epoch 00014: val_loss improved from 1.33299 to 1.32950, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3381 - accuracy: 0.3671 - val_loss: 1.3295 - val_accuracy: 0.3498
Epoch 15/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3055 - accuracy: 0.4219
Epoch 00015: val_loss improved from 1.32950 to 1.32549, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 81us/sample - loss: 1.3293 - accuracy: 0.3770 - val_loss: 1.3255 - val_accuracy: 0.3617
Epoch 16/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3870 - accuracy: 0.2969
Epoch 00016: val_loss improved from 1.32549 to 1.32103, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3227 - accuracy: 0.3730 - val_loss: 1.3210 - val_accuracy: 0.3735
Epoch 17/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3205 - accuracy: 0.3750
Epoch 00017: val_loss improved from 1.32103 to 1.31594, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3081 - accuracy: 0.3988 - val_loss: 1.3159 - val_accuracy: 0.3972
Epoch 18/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3185 - accuracy: 0.3906
Epoch 00018: val_loss improved from 1.31594 to 1.31314, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2947 - accuracy: 0.4177 - val_loss: 1.3131 - val_accuracy: 0.4071
Epoch 19/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2668 - accuracy: 0.5000
Epoch 00019: val_loss improved from 1.31314 to 1.30726, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2981 - accuracy: 0.4177 - val_loss: 1.3073 - val_accuracy: 0.4170
Epoch 20/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2268 - accuracy: 0.5156
Epoch 00020: val_loss improved from 1.30726 to 1.30383, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3032 - accuracy: 0.4087 - val_loss: 1.3038 - val_accuracy: 0.4209
Epoch 21/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3196 - accuracy: 0.4375
Epoch 00021: val_loss improved from 1.30383 to 1.29667, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3056 - accuracy: 0.4216 - val_loss: 1.2967 - val_accuracy: 0.4229
Epoch 22/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3237 - accuracy: 0.3594
Epoch 00022: val_loss improved from 1.29667 to 1.29179, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3078 - accuracy: 0.4206 - val_loss: 1.2918 - val_accuracy: 0.4447
Epoch 23/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2886 - accuracy: 0.4219
Epoch 00023: val_loss improved from 1.29179 to 1.28748, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2957 - accuracy: 0.4286 - val_loss: 1.2875 - val_accuracy: 0.4427
Epoch 24/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2719 - accuracy: 0.4844
Epoch 00024: val_loss improved from 1.28748 to 1.28607, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2962 - accuracy: 0.4296 - val_loss: 1.2861 - val_accuracy: 0.4427
Epoch 25/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2461 - accuracy: 0.4688
Epoch 00025: val_loss improved from 1.28607 to 1.28190, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2823 - accuracy: 0.4415 - val_loss: 1.2819 - val_accuracy: 0.4447
Epoch 26/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2200 - accuracy: 0.5312
Epoch 00026: val_loss improved from 1.28190 to 1.27899, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2826 - accuracy: 0.4464 - val_loss: 1.2790 - val_accuracy: 0.4486
Epoch 27/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2691 - accuracy: 0.5156
Epoch 00027: val_loss improved from 1.27899 to 1.27572, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.2745 - accuracy: 0.4504 - val_loss: 1.2757 - val_accuracy: 0.4545
Epoch 28/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2298 - accuracy: 0.5156
Epoch 00028: val_loss improved from 1.27572 to 1.26767, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2652 - accuracy: 0.4702 - val_loss: 1.2677 - val_accuracy: 0.4723
Epoch 29/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2323 - accuracy: 0.5469
Epoch 00029: val_loss improved from 1.26767 to 1.26254, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2699 - accuracy: 0.4603 - val_loss: 1.2625 - val_accuracy: 0.4921
Epoch 30/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2180 - accuracy: 0.5469
Epoch 00030: val_loss improved from 1.26254 to 1.25497, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2701 - accuracy: 0.4593 - val_loss: 1.2550 - val_accuracy: 0.5099
Epoch 31/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2454 - accuracy: 0.4844
Epoch 00031: val_loss improved from 1.25497 to 1.25081, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2680 - accuracy: 0.4613 - val_loss: 1.2508 - val_accuracy: 0.5099
Epoch 32/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2167 - accuracy: 0.4844
Epoch 00032: val_loss improved from 1.25081 to 1.24539, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.2685 - accuracy: 0.4603 - val_loss: 1.2454 - val_accuracy: 0.5119
Epoch 33/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3371 - accuracy: 0.3594
Epoch 00033: val_loss improved from 1.24539 to 1.24115, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2629 - accuracy: 0.4643 - val_loss: 1.2411 - val_accuracy: 0.5158
Epoch 34/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2297 - accuracy: 0.5000
Epoch 00034: val_loss improved from 1.24115 to 1.23925, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2419 - accuracy: 0.4970 - val_loss: 1.2393 - val_accuracy: 0.5158
Epoch 35/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2701 - accuracy: 0.4375
Epoch 00035: val_loss improved from 1.23925 to 1.23649, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2508 - accuracy: 0.4831 - val_loss: 1.2365 - val_accuracy: 0.5158
Epoch 36/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2630 - accuracy: 0.5000
Epoch 00036: val_loss improved from 1.23649 to 1.23519, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2675 - accuracy: 0.4683 - val_loss: 1.2352 - val_accuracy: 0.5178
Epoch 37/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2330 - accuracy: 0.5156
Epoch 00037: val_loss improved from 1.23519 to 1.23288, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2469 - accuracy: 0.4821 - val_loss: 1.2329 - val_accuracy: 0.5158
Epoch 38/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1644 - accuracy: 0.5625
Epoch 00038: val_loss improved from 1.23288 to 1.23232, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2443 - accuracy: 0.5040 - val_loss: 1.2323 - val_accuracy: 0.5178
Epoch 39/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2306 - accuracy: 0.5000
Epoch 00039: val_loss improved from 1.23232 to 1.23004, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2315 - accuracy: 0.5109 - val_loss: 1.2300 - val_accuracy: 0.5178
Epoch 40/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2893 - accuracy: 0.4531
Epoch 00040: val_loss improved from 1.23004 to 1.22844, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2399 - accuracy: 0.4950 - val_loss: 1.2284 - val_accuracy: 0.5198
Epoch 41/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1676 - accuracy: 0.6094
Epoch 00041: val_loss improved from 1.22844 to 1.22685, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 87us/sample - loss: 1.2245 - accuracy: 0.5208 - val_loss: 1.2268 - val_accuracy: 0.5217
Epoch 42/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2432 - accuracy: 0.4844
Epoch 00042: val_loss improved from 1.22685 to 1.22560, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2426 - accuracy: 0.4792 - val_loss: 1.2256 - val_accuracy: 0.5237
Epoch 43/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1758 - accuracy: 0.6094
Epoch 00043: val_loss improved from 1.22560 to 1.22482, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2281 - accuracy: 0.5109 - val_loss: 1.2248 - val_accuracy: 0.5277
Epoch 44/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2385 - accuracy: 0.5312
Epoch 00044: val_loss improved from 1.22482 to 1.22245, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2321 - accuracy: 0.5109 - val_loss: 1.2225 - val_accuracy: 0.5237
Epoch 45/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2684 - accuracy: 0.4844
Epoch 00045: val_loss improved from 1.22245 to 1.22119, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2067 - accuracy: 0.5456 - val_loss: 1.2212 - val_accuracy: 0.5198
Epoch 46/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2121 - accuracy: 0.5625
Epoch 00046: val_loss did not improve from 1.22119
1008/1008 [==============================] - 0s 69us/sample - loss: 1.2189 - accuracy: 0.5228 - val_loss: 1.2213 - val_accuracy: 0.5237
Epoch 47/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2233 - accuracy: 0.4844
Epoch 00047: val_loss improved from 1.22119 to 1.21973, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2139 - accuracy: 0.5288 - val_loss: 1.2197 - val_accuracy: 0.5296
Epoch 48/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1859 - accuracy: 0.5781
Epoch 00048: val_loss improved from 1.21973 to 1.21825, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2077 - accuracy: 0.5367 - val_loss: 1.2183 - val_accuracy: 0.5257
Epoch 49/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2339 - accuracy: 0.5156
Epoch 00049: val_loss improved from 1.21825 to 1.21778, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2042 - accuracy: 0.5456 - val_loss: 1.2178 - val_accuracy: 0.5277
Epoch 50/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1795 - accuracy: 0.5938
Epoch 00050: val_loss improved from 1.21778 to 1.21624, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2138 - accuracy: 0.5298 - val_loss: 1.2162 - val_accuracy: 0.5316
Epoch 51/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2196 - accuracy: 0.5156
Epoch 00051: val_loss improved from 1.21624 to 1.21579, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1906 - accuracy: 0.5685 - val_loss: 1.2158 - val_accuracy: 0.5395
Epoch 52/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2078 - accuracy: 0.5625 960/1008 [===========================>..] - ETA: 0s - loss: 1.2179 - accuracy: 0.5240
Epoch 00052: val_loss did not improve from 1.21579
1008/1008 [==============================] - 0s 89us/sample - loss: 1.2161 - accuracy: 0.5258 - val_loss: 1.2166 - val_accuracy: 0.5375
Epoch 53/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2266 - accuracy: 0.5000
Epoch 00053: val_loss did not improve from 1.21579
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1859 - accuracy: 0.5724 - val_loss: 1.2161 - val_accuracy: 0.5395
Epoch 54/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1967 - accuracy: 0.5625
Epoch 00054: val_loss did not improve from 1.21579
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2085 - accuracy: 0.5427 - val_loss: 1.2159 - val_accuracy: 0.5316
Epoch 55/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2039 - accuracy: 0.4844
Epoch 00055: val_loss improved from 1.21579 to 1.21563, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1917 - accuracy: 0.5516 - val_loss: 1.2156 - val_accuracy: 0.5316
Epoch 56/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2306 - accuracy: 0.5000
Epoch 00056: val_loss improved from 1.21563 to 1.21419, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1743 - accuracy: 0.5863 - val_loss: 1.2142 - val_accuracy: 0.5316
Epoch 57/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0958 - accuracy: 0.7031
Epoch 00057: val_loss improved from 1.21419 to 1.21379, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1859 - accuracy: 0.5675 - val_loss: 1.2138 - val_accuracy: 0.5296
Epoch 58/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2376 - accuracy: 0.5000
Epoch 00058: val_loss improved from 1.21379 to 1.21287, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1791 - accuracy: 0.5734 - val_loss: 1.2129 - val_accuracy: 0.5277
Epoch 59/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1850 - accuracy: 0.5625
Epoch 00059: val_loss improved from 1.21287 to 1.21150, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1706 - accuracy: 0.5863 - val_loss: 1.2115 - val_accuracy: 0.5257
Epoch 60/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1736 - accuracy: 0.5625
Epoch 00060: val_loss improved from 1.21150 to 1.21048, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1601 - accuracy: 0.5933 - val_loss: 1.2105 - val_accuracy: 0.5316
Epoch 61/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1671 - accuracy: 0.5781
Epoch 00061: val_loss improved from 1.21048 to 1.20932, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 96us/sample - loss: 1.1665 - accuracy: 0.5843 - val_loss: 1.2093 - val_accuracy: 0.5316
Epoch 62/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1839 - accuracy: 0.5469 960/1008 [===========================>..] - ETA: 0s - loss: 1.1636 - accuracy: 0.6010
Epoch 00062: val_loss improved from 1.20932 to 1.20862, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 97us/sample - loss: 1.1640 - accuracy: 0.5992 - val_loss: 1.2086 - val_accuracy: 0.5336
Epoch 63/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1244 - accuracy: 0.6250 960/1008 [===========================>..] - ETA: 0s - loss: 1.1527 - accuracy: 0.6135
Epoch 00063: val_loss improved from 1.20862 to 1.20741, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 96us/sample - loss: 1.1560 - accuracy: 0.6111 - val_loss: 1.2074 - val_accuracy: 0.5415
Epoch 64/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1638 - accuracy: 0.6406
Epoch 00064: val_loss improved from 1.20741 to 1.20596, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1479 - accuracy: 0.6161 - val_loss: 1.2060 - val_accuracy: 0.5415
Epoch 65/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1703 - accuracy: 0.6250
Epoch 00065: val_loss did not improve from 1.20596
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1605 - accuracy: 0.6052 - val_loss: 1.2063 - val_accuracy: 0.5395
Epoch 66/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1758 - accuracy: 0.5781
Epoch 00066: val_loss improved from 1.20596 to 1.20528, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1637 - accuracy: 0.5933 - val_loss: 1.2053 - val_accuracy: 0.5415
Epoch 67/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1667 - accuracy: 0.5781
Epoch 00067: val_loss improved from 1.20528 to 1.20351, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1515 - accuracy: 0.6062 - val_loss: 1.2035 - val_accuracy: 0.5435
Epoch 68/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1789 - accuracy: 0.5938 896/1008 [=========================>....] - ETA: 0s - loss: 1.1483 - accuracy: 0.6150
Epoch 00068: val_loss improved from 1.20351 to 1.20237, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 101us/sample - loss: 1.1459 - accuracy: 0.6141 - val_loss: 1.2024 - val_accuracy: 0.5494
Epoch 69/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1247 - accuracy: 0.6406 960/1008 [===========================>..] - ETA: 0s - loss: 1.1269 - accuracy: 0.6427
Epoch 00069: val_loss did not improve from 1.20237
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1289 - accuracy: 0.6399 - val_loss: 1.2028 - val_accuracy: 0.5415
Epoch 70/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1750 - accuracy: 0.5469 960/1008 [===========================>..] - ETA: 0s - loss: 1.1505 - accuracy: 0.6010
Epoch 00070: val_loss improved from 1.20237 to 1.20233, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 95us/sample - loss: 1.1497 - accuracy: 0.6032 - val_loss: 1.2023 - val_accuracy: 0.5474
Epoch 71/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1290 - accuracy: 0.6562
Epoch 00071: val_loss improved from 1.20233 to 1.20196, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1465 - accuracy: 0.6111 - val_loss: 1.2020 - val_accuracy: 0.5494
Epoch 72/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1956 - accuracy: 0.5156
Epoch 00072: val_loss improved from 1.20196 to 1.20042, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1335 - accuracy: 0.6210 - val_loss: 1.2004 - val_accuracy: 0.5494
Epoch 73/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1114 - accuracy: 0.6406
Epoch 00073: val_loss improved from 1.20042 to 1.20033, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1320 - accuracy: 0.6240 - val_loss: 1.2003 - val_accuracy: 0.5474
Epoch 74/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0683 - accuracy: 0.7656
Epoch 00074: val_loss improved from 1.20033 to 1.19942, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1245 - accuracy: 0.6399 - val_loss: 1.1994 - val_accuracy: 0.5494
Epoch 75/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1267 - accuracy: 0.6250
Epoch 00075: val_loss improved from 1.19942 to 1.19717, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 87us/sample - loss: 1.1275 - accuracy: 0.6300 - val_loss: 1.1972 - val_accuracy: 0.5474
Epoch 76/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1670 - accuracy: 0.5938
Epoch 00076: val_loss improved from 1.19717 to 1.19423, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1293 - accuracy: 0.6290 - val_loss: 1.1942 - val_accuracy: 0.5455
Epoch 77/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1190 - accuracy: 0.6250
Epoch 00077: val_loss improved from 1.19423 to 1.19385, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1229 - accuracy: 0.6329 - val_loss: 1.1939 - val_accuracy: 0.5455
Epoch 78/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0645 - accuracy: 0.7188
Epoch 00078: val_loss improved from 1.19385 to 1.19354, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1368 - accuracy: 0.6121 - val_loss: 1.1935 - val_accuracy: 0.5474
Epoch 79/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0396 - accuracy: 0.7969
Epoch 00079: val_loss improved from 1.19354 to 1.19128, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1148 - accuracy: 0.6458 - val_loss: 1.1913 - val_accuracy: 0.5455
Epoch 80/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2025 - accuracy: 0.5156
Epoch 00080: val_loss improved from 1.19128 to 1.18964, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1173 - accuracy: 0.6438 - val_loss: 1.1896 - val_accuracy: 0.5494
Epoch 81/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0822 - accuracy: 0.6562
Epoch 00081: val_loss improved from 1.18964 to 1.18852, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1181 - accuracy: 0.6399 - val_loss: 1.1885 - val_accuracy: 0.5553
Epoch 82/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1349 - accuracy: 0.6406
Epoch 00082: val_loss improved from 1.18852 to 1.18795, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1278 - accuracy: 0.6310 - val_loss: 1.1879 - val_accuracy: 0.5494
Epoch 83/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0941 - accuracy: 0.7188
Epoch 00083: val_loss improved from 1.18795 to 1.18702, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1237 - accuracy: 0.6468 - val_loss: 1.1870 - val_accuracy: 0.5494
Epoch 84/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1534 - accuracy: 0.6094
Epoch 00084: val_loss did not improve from 1.18702
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1180 - accuracy: 0.6339 - val_loss: 1.1874 - val_accuracy: 0.5514
Epoch 85/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1491 - accuracy: 0.6406
Epoch 00085: val_loss did not improve from 1.18702
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0955 - accuracy: 0.6756 - val_loss: 1.1880 - val_accuracy: 0.5514
Epoch 86/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1198 - accuracy: 0.6406
Epoch 00086: val_loss improved from 1.18702 to 1.18688, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 81us/sample - loss: 1.0942 - accuracy: 0.6647 - val_loss: 1.1869 - val_accuracy: 0.5553
Epoch 87/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1243 - accuracy: 0.6250
Epoch 00087: val_loss did not improve from 1.18688
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0981 - accuracy: 0.6696 - val_loss: 1.1869 - val_accuracy: 0.5573
Epoch 88/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0686 - accuracy: 0.7031
Epoch 00088: val_loss improved from 1.18688 to 1.18607, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1023 - accuracy: 0.6538 - val_loss: 1.1861 - val_accuracy: 0.5514
Epoch 89/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0788 - accuracy: 0.6719
Epoch 00089: val_loss improved from 1.18607 to 1.18386, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1073 - accuracy: 0.6528 - val_loss: 1.1839 - val_accuracy: 0.5573
Epoch 90/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0734 - accuracy: 0.7188
Epoch 00090: val_loss improved from 1.18386 to 1.18345, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.6815 - val_loss: 1.1835 - val_accuracy: 0.5573
Epoch 91/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0382 - accuracy: 0.7188
Epoch 00091: val_loss did not improve from 1.18345
1008/1008 [==============================] - 0s 73us/sample - loss: 1.1035 - accuracy: 0.6567 - val_loss: 1.1839 - val_accuracy: 0.5613
Epoch 92/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0578 - accuracy: 0.7031
Epoch 00092: val_loss improved from 1.18345 to 1.18312, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0945 - accuracy: 0.6587 - val_loss: 1.1831 - val_accuracy: 0.5593
Epoch 93/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0939 - accuracy: 0.7188
Epoch 00093: val_loss did not improve from 1.18312
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1021 - accuracy: 0.6548 - val_loss: 1.1849 - val_accuracy: 0.5593
Epoch 94/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1883 - accuracy: 0.5781
Epoch 00094: val_loss did not improve from 1.18312
1008/1008 [==============================] - 0s 69us/sample - loss: 1.0936 - accuracy: 0.6667 - val_loss: 1.1846 - val_accuracy: 0.5553
Epoch 95/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1110 - accuracy: 0.6094
Epoch 00095: val_loss did not improve from 1.18312
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0981 - accuracy: 0.6835 - val_loss: 1.1853 - val_accuracy: 0.5514
Epoch 96/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1284 - accuracy: 0.6094
Epoch 00096: val_loss did not improve from 1.18312
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0812 - accuracy: 0.6756 - val_loss: 1.1847 - val_accuracy: 0.5534
Epoch 97/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1153 - accuracy: 0.6250
Epoch 00097: val_loss did not improve from 1.18312
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0862 - accuracy: 0.6746 - val_loss: 1.1839 - val_accuracy: 0.5534
Epoch 98/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0668 - accuracy: 0.7031
Epoch 00098: val_loss improved from 1.18312 to 1.18292, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0706 - accuracy: 0.6835 - val_loss: 1.1829 - val_accuracy: 0.5534
Epoch 99/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1089 - accuracy: 0.6406
Epoch 00099: val_loss did not improve from 1.18292
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0807 - accuracy: 0.6796 - val_loss: 1.1829 - val_accuracy: 0.5474
Epoch 100/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1099 - accuracy: 0.6250
Epoch 00100: val_loss did not improve from 1.18292
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0715 - accuracy: 0.6925 - val_loss: 1.1838 - val_accuracy: 0.5455
Epoch 101/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0557 - accuracy: 0.7188
Epoch 00101: val_loss did not improve from 1.18292
1008/1008 [==============================] - 0s 73us/sample - loss: 1.0685 - accuracy: 0.7103 - val_loss: 1.1831 - val_accuracy: 0.5534
Epoch 102/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0335 - accuracy: 0.7656
Epoch 00102: val_loss improved from 1.18292 to 1.18248, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.0749 - accuracy: 0.6865 - val_loss: 1.1825 - val_accuracy: 0.5672
Epoch 103/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1057 - accuracy: 0.6094
Epoch 00103: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0688 - accuracy: 0.6895 - val_loss: 1.1837 - val_accuracy: 0.5593
Epoch 104/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0452 - accuracy: 0.7344
Epoch 00104: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 69us/sample - loss: 1.0820 - accuracy: 0.6825 - val_loss: 1.1855 - val_accuracy: 0.5534
Epoch 105/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0603 - accuracy: 0.6875
Epoch 00105: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0552 - accuracy: 0.6994 - val_loss: 1.1874 - val_accuracy: 0.5474
Epoch 106/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0758 - accuracy: 0.6719
Epoch 00106: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0511 - accuracy: 0.7143 - val_loss: 1.1878 - val_accuracy: 0.5494
Epoch 107/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0392 - accuracy: 0.7344
Epoch 00107: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0596 - accuracy: 0.7103 - val_loss: 1.1864 - val_accuracy: 0.5573
Epoch 108/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0513 - accuracy: 0.7031
Epoch 00108: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 69us/sample - loss: 1.0567 - accuracy: 0.7004 - val_loss: 1.1835 - val_accuracy: 0.5613
Epoch 109/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0589 - accuracy: 0.7344
Epoch 00109: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0507 - accuracy: 0.7183 - val_loss: 1.1840 - val_accuracy: 0.5632
Epoch 110/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0500 - accuracy: 0.7656
Epoch 00110: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0643 - accuracy: 0.6895 - val_loss: 1.1857 - val_accuracy: 0.5573
Epoch 111/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0867 - accuracy: 0.6875
Epoch 00111: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0580 - accuracy: 0.7004 - val_loss: 1.1857 - val_accuracy: 0.5593
Epoch 112/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9329 - accuracy: 0.8594
Epoch 00112: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0496 - accuracy: 0.7073 - val_loss: 1.1847 - val_accuracy: 0.5553
Epoch 113/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0039 - accuracy: 0.8281
Epoch 00113: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0430 - accuracy: 0.7222 - val_loss: 1.1842 - val_accuracy: 0.5573
Epoch 114/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9797 - accuracy: 0.7969
Epoch 00114: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0419 - accuracy: 0.7222 - val_loss: 1.1837 - val_accuracy: 0.5494
Epoch 115/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0834 - accuracy: 0.6719 960/1008 [===========================>..] - ETA: 0s - loss: 1.0428 - accuracy: 0.7156
Epoch 00115: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 86us/sample - loss: 1.0456 - accuracy: 0.7113 - val_loss: 1.1836 - val_accuracy: 0.5573
Epoch 116/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0966 - accuracy: 0.6562
Epoch 00116: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0416 - accuracy: 0.7173 - val_loss: 1.1828 - val_accuracy: 0.5613
Epoch 117/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9819 - accuracy: 0.8125
Epoch 00117: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0431 - accuracy: 0.7173 - val_loss: 1.1842 - val_accuracy: 0.5534
Epoch 118/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0922 - accuracy: 0.6562
Epoch 00118: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0434 - accuracy: 0.7212 - val_loss: 1.1854 - val_accuracy: 0.5553
Epoch 119/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1278 - accuracy: 0.6094
Epoch 00119: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0422 - accuracy: 0.7212 - val_loss: 1.1841 - val_accuracy: 0.5553
Epoch 120/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0427 - accuracy: 0.7344
Epoch 00120: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0293 - accuracy: 0.7331 - val_loss: 1.1829 - val_accuracy: 0.5593
Epoch 121/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1014 - accuracy: 0.6250
Epoch 00121: val_loss did not improve from 1.18248
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0463 - accuracy: 0.7163 - val_loss: 1.1834 - val_accuracy: 0.5553
Epoch 122/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9941 - accuracy: 0.7812
Epoch 00122: val_loss improved from 1.18248 to 1.18097, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0381 - accuracy: 0.7133 - val_loss: 1.1810 - val_accuracy: 0.5573
Epoch 123/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0258 - accuracy: 0.6875
Epoch 00123: val_loss improved from 1.18097 to 1.18067, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0314 - accuracy: 0.7212 - val_loss: 1.1807 - val_accuracy: 0.5593
Epoch 124/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0243 - accuracy: 0.7188
Epoch 00124: val_loss did not improve from 1.18067
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0248 - accuracy: 0.7302 - val_loss: 1.1816 - val_accuracy: 0.5553
Epoch 125/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9899 - accuracy: 0.8125
Epoch 00125: val_loss did not improve from 1.18067
1008/1008 [==============================] - 0s 69us/sample - loss: 1.0284 - accuracy: 0.7321 - val_loss: 1.1818 - val_accuracy: 0.5573
Epoch 126/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9992 - accuracy: 0.7500
Epoch 00126: val_loss improved from 1.18067 to 1.18026, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0355 - accuracy: 0.7252 - val_loss: 1.1803 - val_accuracy: 0.5692
Epoch 127/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0942 - accuracy: 0.7188
Epoch 00127: val_loss improved from 1.18026 to 1.17979, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0438 - accuracy: 0.7183 - val_loss: 1.1798 - val_accuracy: 0.5632
Epoch 128/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9862 - accuracy: 0.7500
Epoch 00128: val_loss improved from 1.17979 to 1.17948, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.0267 - accuracy: 0.7381 - val_loss: 1.1795 - val_accuracy: 0.5613
Epoch 129/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0505 - accuracy: 0.7344
Epoch 00129: val_loss improved from 1.17948 to 1.17932, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.0359 - accuracy: 0.7282 - val_loss: 1.1793 - val_accuracy: 0.5514
Epoch 130/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9963 - accuracy: 0.7656
Epoch 00130: val_loss did not improve from 1.17932
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0185 - accuracy: 0.7391 - val_loss: 1.1799 - val_accuracy: 0.5553
Epoch 131/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9613 - accuracy: 0.8125
Epoch 00131: val_loss improved from 1.17932 to 1.17892, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0270 - accuracy: 0.7351 - val_loss: 1.1789 - val_accuracy: 0.5573
Epoch 132/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9588 - accuracy: 0.8438
Epoch 00132: val_loss improved from 1.17892 to 1.17807, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0129 - accuracy: 0.7490 - val_loss: 1.1781 - val_accuracy: 0.5613
Epoch 133/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0826 - accuracy: 0.7344
Epoch 00133: val_loss did not improve from 1.17807
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0292 - accuracy: 0.7341 - val_loss: 1.1795 - val_accuracy: 0.5652
Epoch 134/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9604 - accuracy: 0.8281
Epoch 00134: val_loss did not improve from 1.17807
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0158 - accuracy: 0.7351 - val_loss: 1.1792 - val_accuracy: 0.5632
Epoch 135/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9998 - accuracy: 0.7031
Epoch 00135: val_loss improved from 1.17807 to 1.17701, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0109 - accuracy: 0.7470 - val_loss: 1.1770 - val_accuracy: 0.5632
Epoch 136/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0095 - accuracy: 0.7500
Epoch 00136: val_loss did not improve from 1.17701
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0147 - accuracy: 0.7520 - val_loss: 1.1784 - val_accuracy: 0.5632
Epoch 137/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9959 - accuracy: 0.7812
Epoch 00137: val_loss did not improve from 1.17701
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0083 - accuracy: 0.7530 - val_loss: 1.1782 - val_accuracy: 0.5632
Epoch 138/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9687 - accuracy: 0.7969
Epoch 00138: val_loss did not improve from 1.17701
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0178 - accuracy: 0.7460 - val_loss: 1.1781 - val_accuracy: 0.5652
Epoch 139/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0896 - accuracy: 0.6250
Epoch 00139: val_loss did not improve from 1.17701
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0031 - accuracy: 0.7569 - val_loss: 1.1792 - val_accuracy: 0.5632
Epoch 140/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0048 - accuracy: 0.7656
Epoch 00140: val_loss improved from 1.17701 to 1.17699, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0007 - accuracy: 0.7629 - val_loss: 1.1770 - val_accuracy: 0.5731
Epoch 141/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9688 - accuracy: 0.7969
Epoch 00141: val_loss improved from 1.17699 to 1.17695, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.0031 - accuracy: 0.7599 - val_loss: 1.1770 - val_accuracy: 0.5632
Epoch 142/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9436 - accuracy: 0.8438
Epoch 00142: val_loss did not improve from 1.17695
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0119 - accuracy: 0.7440 - val_loss: 1.1777 - val_accuracy: 0.5613
Epoch 143/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0262 - accuracy: 0.7344
Epoch 00143: val_loss improved from 1.17695 to 1.17510, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0089 - accuracy: 0.7569 - val_loss: 1.1751 - val_accuracy: 0.5672
Epoch 144/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0019 - accuracy: 0.7812
Epoch 00144: val_loss improved from 1.17510 to 1.17337, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0036 - accuracy: 0.7589 - val_loss: 1.1734 - val_accuracy: 0.5711
Epoch 145/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0064 - accuracy: 0.7656
Epoch 00145: val_loss did not improve from 1.17337
1008/1008 [==============================] - 0s 71us/sample - loss: 0.9969 - accuracy: 0.7609 - val_loss: 1.1734 - val_accuracy: 0.5632
Epoch 146/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9845 - accuracy: 0.7500
Epoch 00146: val_loss did not improve from 1.17337
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0120 - accuracy: 0.7440 - val_loss: 1.1743 - val_accuracy: 0.5613
Epoch 147/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0852 - accuracy: 0.6719
Epoch 00147: val_loss did not improve from 1.17337
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0113 - accuracy: 0.7440 - val_loss: 1.1762 - val_accuracy: 0.5652
Epoch 148/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0454 - accuracy: 0.7031
Epoch 00148: val_loss did not improve from 1.17337
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0064 - accuracy: 0.7569 - val_loss: 1.1744 - val_accuracy: 0.5672
Epoch 149/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0449 - accuracy: 0.6719
Epoch 00149: val_loss improved from 1.17337 to 1.17177, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.0017 - accuracy: 0.7490 - val_loss: 1.1718 - val_accuracy: 0.5632
Epoch 150/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0379 - accuracy: 0.6875
Epoch 00150: val_loss did not improve from 1.17177
1008/1008 [==============================] - 0s 74us/sample - loss: 0.9990 - accuracy: 0.7599 - val_loss: 1.1734 - val_accuracy: 0.5652
Epoch 151/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0229 - accuracy: 0.7344
Epoch 00151: val_loss did not improve from 1.17177
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0065 - accuracy: 0.7450 - val_loss: 1.1740 - val_accuracy: 0.5632
Epoch 152/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9651 - accuracy: 0.7969
Epoch 00152: val_loss improved from 1.17177 to 1.17137, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 0.9841 - accuracy: 0.7788 - val_loss: 1.1714 - val_accuracy: 0.5672
Epoch 153/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9803 - accuracy: 0.7656
Epoch 00153: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 78us/sample - loss: 0.9868 - accuracy: 0.7768 - val_loss: 1.1723 - val_accuracy: 0.5672
Epoch 154/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9944 - accuracy: 0.7500
Epoch 00154: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 69us/sample - loss: 0.9890 - accuracy: 0.7768 - val_loss: 1.1744 - val_accuracy: 0.5652
Epoch 155/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9575 - accuracy: 0.8125
Epoch 00155: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9978 - accuracy: 0.7569 - val_loss: 1.1751 - val_accuracy: 0.5593
Epoch 156/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9501 - accuracy: 0.7812
Epoch 00156: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 69us/sample - loss: 0.9989 - accuracy: 0.7589 - val_loss: 1.1766 - val_accuracy: 0.5613
Epoch 157/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0371 - accuracy: 0.7031
Epoch 00157: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 69us/sample - loss: 1.0055 - accuracy: 0.7460 - val_loss: 1.1751 - val_accuracy: 0.5632
Epoch 158/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9185 - accuracy: 0.8281
Epoch 00158: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 69us/sample - loss: 0.9881 - accuracy: 0.7639 - val_loss: 1.1741 - val_accuracy: 0.5593
Epoch 159/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9617 - accuracy: 0.7969
Epoch 00159: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9867 - accuracy: 0.7688 - val_loss: 1.1733 - val_accuracy: 0.5652
Epoch 160/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0318 - accuracy: 0.7031
Epoch 00160: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 69us/sample - loss: 0.9975 - accuracy: 0.7579 - val_loss: 1.1735 - val_accuracy: 0.5652
Epoch 161/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9349 - accuracy: 0.8438
Epoch 00161: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 71us/sample - loss: 0.9850 - accuracy: 0.7748 - val_loss: 1.1742 - val_accuracy: 0.5632
Epoch 162/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9112 - accuracy: 0.8906
Epoch 00162: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 71us/sample - loss: 0.9823 - accuracy: 0.7758 - val_loss: 1.1742 - val_accuracy: 0.5553
Epoch 163/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0238 - accuracy: 0.7188 960/1008 [===========================>..] - ETA: 0s - loss: 0.9875 - accuracy: 0.7708
Epoch 00163: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 80us/sample - loss: 0.9877 - accuracy: 0.7718 - val_loss: 1.1744 - val_accuracy: 0.5534
Epoch 164/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9790 - accuracy: 0.7812 960/1008 [===========================>..] - ETA: 0s - loss: 0.9741 - accuracy: 0.7865
Epoch 00164: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 82us/sample - loss: 0.9699 - accuracy: 0.7907 - val_loss: 1.1748 - val_accuracy: 0.5553
Epoch 165/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9649 - accuracy: 0.8125 960/1008 [===========================>..] - ETA: 0s - loss: 0.9837 - accuracy: 0.7729
Epoch 00165: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 83us/sample - loss: 0.9839 - accuracy: 0.7718 - val_loss: 1.1748 - val_accuracy: 0.5553
Epoch 166/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0392 - accuracy: 0.6875 960/1008 [===========================>..] - ETA: 0s - loss: 0.9759 - accuracy: 0.7771
Epoch 00166: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 80us/sample - loss: 0.9755 - accuracy: 0.7768 - val_loss: 1.1773 - val_accuracy: 0.5573
Epoch 167/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9845 - accuracy: 0.7656
Epoch 00167: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9774 - accuracy: 0.7837 - val_loss: 1.1771 - val_accuracy: 0.5632
Epoch 168/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9526 - accuracy: 0.7969
Epoch 00168: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9687 - accuracy: 0.7927 - val_loss: 1.1780 - val_accuracy: 0.5534
Epoch 169/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9234 - accuracy: 0.8125
Epoch 00169: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 71us/sample - loss: 0.9702 - accuracy: 0.7808 - val_loss: 1.1755 - val_accuracy: 0.5593
Epoch 170/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9044 - accuracy: 0.8594
Epoch 00170: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9769 - accuracy: 0.7768 - val_loss: 1.1729 - val_accuracy: 0.5573
Epoch 171/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9926 - accuracy: 0.7344
Epoch 00171: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 81us/sample - loss: 0.9699 - accuracy: 0.7808 - val_loss: 1.1723 - val_accuracy: 0.5613
Epoch 172/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9991 - accuracy: 0.7031 960/1008 [===========================>..] - ETA: 0s - loss: 0.9716 - accuracy: 0.7854
Epoch 00172: val_loss did not improve from 1.17137
1008/1008 [==============================] - 0s 82us/sample - loss: 0.9695 - accuracy: 0.7877 - val_loss: 1.1722 - val_accuracy: 0.5613
Epoch 173/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9437 - accuracy: 0.7812 960/1008 [===========================>..] - ETA: 0s - loss: 0.9783 - accuracy: 0.7750
Epoch 00173: val_loss improved from 1.17137 to 1.16979, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 96us/sample - loss: 0.9756 - accuracy: 0.7798 - val_loss: 1.1698 - val_accuracy: 0.5692
Epoch 174/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.8942 - accuracy: 0.9062 960/1008 [===========================>..] - ETA: 0s - loss: 0.9497 - accuracy: 0.7990
Epoch 00174: val_loss improved from 1.16979 to 1.16892, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 95us/sample - loss: 0.9492 - accuracy: 0.8016 - val_loss: 1.1689 - val_accuracy: 0.5652
Epoch 175/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0089 - accuracy: 0.7500
Epoch 00175: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 73us/sample - loss: 0.9723 - accuracy: 0.7956 - val_loss: 1.1692 - val_accuracy: 0.5672
Epoch 176/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9646 - accuracy: 0.7656
Epoch 00176: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9622 - accuracy: 0.7976 - val_loss: 1.1696 - val_accuracy: 0.5632
Epoch 177/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9470 - accuracy: 0.7969
Epoch 00177: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 71us/sample - loss: 0.9618 - accuracy: 0.7877 - val_loss: 1.1699 - val_accuracy: 0.5672
Epoch 178/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9061 - accuracy: 0.8438
Epoch 00178: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9701 - accuracy: 0.7857 - val_loss: 1.1718 - val_accuracy: 0.5652
Epoch 179/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9059 - accuracy: 0.8750
Epoch 00179: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9648 - accuracy: 0.7986 - val_loss: 1.1745 - val_accuracy: 0.5613
Epoch 180/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9179 - accuracy: 0.8594
Epoch 00180: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 76us/sample - loss: 0.9674 - accuracy: 0.7867 - val_loss: 1.1746 - val_accuracy: 0.5573
Epoch 181/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9951 - accuracy: 0.7656
Epoch 00181: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 78us/sample - loss: 0.9703 - accuracy: 0.7887 - val_loss: 1.1728 - val_accuracy: 0.5711
Epoch 182/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9321 - accuracy: 0.7812
Epoch 00182: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 71us/sample - loss: 0.9582 - accuracy: 0.7996 - val_loss: 1.1745 - val_accuracy: 0.5632
Epoch 183/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9896 - accuracy: 0.7656
Epoch 00183: val_loss did not improve from 1.16892
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9551 - accuracy: 0.7986 - val_loss: 1.1712 - val_accuracy: 0.5751
Epoch 184/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0028 - accuracy: 0.7031
Epoch 00184: val_loss improved from 1.16892 to 1.16881, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 0.9561 - accuracy: 0.8016 - val_loss: 1.1688 - val_accuracy: 0.5751
Epoch 185/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9540 - accuracy: 0.7969
Epoch 00185: val_loss improved from 1.16881 to 1.16853, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 80us/sample - loss: 0.9566 - accuracy: 0.7867 - val_loss: 1.1685 - val_accuracy: 0.5672
Epoch 186/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0183 - accuracy: 0.7812
Epoch 00186: val_loss improved from 1.16853 to 1.16831, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 0.9589 - accuracy: 0.8016 - val_loss: 1.1683 - val_accuracy: 0.5692
Epoch 187/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9159 - accuracy: 0.8750
Epoch 00187: val_loss improved from 1.16831 to 1.16799, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 0.9694 - accuracy: 0.7837 - val_loss: 1.1680 - val_accuracy: 0.5672
Epoch 188/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0137 - accuracy: 0.7344
Epoch 00188: val_loss improved from 1.16799 to 1.16749, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 0.9675 - accuracy: 0.7837 - val_loss: 1.1675 - val_accuracy: 0.5771
Epoch 189/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9131 - accuracy: 0.9062
Epoch 00189: val_loss did not improve from 1.16749
1008/1008 [==============================] - 0s 72us/sample - loss: 0.9567 - accuracy: 0.8006 - val_loss: 1.1693 - val_accuracy: 0.5731
Epoch 190/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9606 - accuracy: 0.7656
Epoch 00190: val_loss did not improve from 1.16749
1008/1008 [==============================] - 0s 70us/sample - loss: 0.9596 - accuracy: 0.7907 - val_loss: 1.1704 - val_accuracy: 0.5731
Epoch 191/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0530 - accuracy: 0.6562
Epoch 00191: val_loss did not improve from 1.16749
1008/1008 [==============================] - 0s 71us/sample - loss: 0.9637 - accuracy: 0.7857 - val_loss: 1.1698 - val_accuracy: 0.5711
Epoch 192/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9200 - accuracy: 0.8438
Epoch 00192: val_loss did not improve from 1.16749
1008/1008 [==============================] - 0s 69us/sample - loss: 0.9472 - accuracy: 0.8115 - val_loss: 1.1677 - val_accuracy: 0.5751
Epoch 193/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0076 - accuracy: 0.7344
Epoch 00193: val_loss improved from 1.16749 to 1.16698, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 0.9694 - accuracy: 0.7808 - val_loss: 1.1670 - val_accuracy: 0.5751
Epoch 194/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0465 - accuracy: 0.7188
Epoch 00194: val_loss did not improve from 1.16698
1008/1008 [==============================] - 0s 80us/sample - loss: 0.9576 - accuracy: 0.7956 - val_loss: 1.1670 - val_accuracy: 0.5751
Epoch 195/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9366 - accuracy: 0.8281 960/1008 [===========================>..] - ETA: 0s - loss: 0.9583 - accuracy: 0.8062
Epoch 00195: val_loss improved from 1.16698 to 1.16697, saving model to saved_models/CountVectorizer_bestloss
1008/1008 [==============================] - 0s 96us/sample - loss: 0.9611 - accuracy: 0.8036 - val_loss: 1.1670 - val_accuracy: 0.5751
Epoch 196/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9579 - accuracy: 0.8125 960/1008 [===========================>..] - ETA: 0s - loss: 0.9396 - accuracy: 0.8219
Epoch 00196: val_loss did not improve from 1.16697
1008/1008 [==============================] - 0s 83us/sample - loss: 0.9390 - accuracy: 0.8214 - val_loss: 1.1694 - val_accuracy: 0.5731
Epoch 197/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9569 - accuracy: 0.7812
Epoch 00197: val_loss did not improve from 1.16697
1008/1008 [==============================] - 0s 77us/sample - loss: 0.9535 - accuracy: 0.7996 - val_loss: 1.1705 - val_accuracy: 0.5692
Epoch 198/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9322 - accuracy: 0.7969 960/1008 [===========================>..] - ETA: 0s - loss: 0.9407 - accuracy: 0.8125
Epoch 00198: val_loss did not improve from 1.16697
1008/1008 [==============================] - 0s 82us/sample - loss: 0.9387 - accuracy: 0.8155 - val_loss: 1.1726 - val_accuracy: 0.5593
Epoch 199/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9493 - accuracy: 0.8281 960/1008 [===========================>..] - ETA: 0s - loss: 0.9649 - accuracy: 0.7948
Epoch 00199: val_loss did not improve from 1.16697
1008/1008 [==============================] - 0s 84us/sample - loss: 0.9617 - accuracy: 0.7976 - val_loss: 1.1728 - val_accuracy: 0.5553
Epoch 200/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9606 - accuracy: 0.7812 960/1008 [===========================>..] - ETA: 0s - loss: 0.9459 - accuracy: 0.8156
Epoch 00200: val_loss did not improve from 1.16697
1008/1008 [==============================] - 0s 81us/sample - loss: 0.9484 - accuracy: 0.8145 - val_loss: 1.1738 - val_accuracy: 0.5593

Results of vectorizer CountVectorizer using a dnn:
acc   = 0.575098814229249
macro = (0.44553147625997136, 0.399144716196917, 0.3730983563841493, None)

Results of vectorizer HashingVectorizer using a SVM with kernel type linear:
acc   = 0.575098814229249
macro = (0.4759632034632034, 0.4015224682264395, 0.37681881858067245, None)

Results of vectorizer HashingVectorizer using a SVM with kernel type poly:
acc   = 0.49604743083003955
macro = (0.3100417895771878, 0.30589216719353707, 0.25573770491803277, None)

Results of vectorizer HashingVectorizer using a SVM with kernel type rbf:
acc   = 0.5434782608695652
macro = (0.2925813736347252, 0.350346856340007, 0.30535253525352535, None)

Results of vectorizer HashingVectorizer using a SVM with kernel type sigmoid:
acc   = 0.4407114624505929
macro = (0.23812993482062425, 0.31265367053038284, 0.2529203956665097, None)

Results of vectorizer TfidfTransformer using a SVM with kernel type linear:
acc   = 0.567193675889328
macro = (0.4285684447326886, 0.3896152343624917, 0.3570172937144808, None)

Results of vectorizer TfidfTransformer using a SVM with kernel type poly:
acc   = 0.49407114624505927
macro = (0.3087383897705027, 0.30428960309097297, 0.25359207678286627, None)

Results of vectorizer TfidfTransformer using a SVM with kernel type rbf:
acc   = 0.5375494071146245
macro = (0.2894341290893015, 0.3455391640323147, 0.3006254225828262, None)

Results of vectorizer TfidfTransformer using a SVM with kernel type sigmoid:
acc   = 0.4407114624505929
macro = (0.23812993482062425, 0.31265367053038284, 0.2529203956665097, None)
Train on 1008 samples, validate on 506 samples
Epoch 1/200
  64/1008 [>.............................] - ETA: 10s - loss: 1.4102 - accuracy: 0.2812 832/1008 [=======================>......] - ETA: 0s - loss: 1.4143 - accuracy: 0.2632 
Epoch 00001: val_loss improved from inf to 1.40047, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 1s 898us/sample - loss: 1.4156 - accuracy: 0.2619 - val_loss: 1.4005 - val_accuracy: 0.1225
Epoch 2/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4159 - accuracy: 0.2344
Epoch 00002: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 71us/sample - loss: 1.4099 - accuracy: 0.2579 - val_loss: 1.4108 - val_accuracy: 0.1225
Epoch 3/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4597 - accuracy: 0.1719
Epoch 00003: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 70us/sample - loss: 1.4005 - accuracy: 0.2679 - val_loss: 1.4165 - val_accuracy: 0.1225
Epoch 4/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4209 - accuracy: 0.1875
Epoch 00004: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 70us/sample - loss: 1.3903 - accuracy: 0.2808 - val_loss: 1.4196 - val_accuracy: 0.1225
Epoch 5/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4417 - accuracy: 0.2656
Epoch 00005: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 71us/sample - loss: 1.3849 - accuracy: 0.3026 - val_loss: 1.4212 - val_accuracy: 0.1225
Epoch 6/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3549 - accuracy: 0.3281
Epoch 00006: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 71us/sample - loss: 1.3922 - accuracy: 0.2827 - val_loss: 1.4190 - val_accuracy: 0.1344
Epoch 7/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3735 - accuracy: 0.2344 960/1008 [===========================>..] - ETA: 0s - loss: 1.3757 - accuracy: 0.2844
Epoch 00007: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3753 - accuracy: 0.2847 - val_loss: 1.4191 - val_accuracy: 0.1542
Epoch 8/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3770 - accuracy: 0.3125 960/1008 [===========================>..] - ETA: 0s - loss: 1.3895 - accuracy: 0.2771
Epoch 00008: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3900 - accuracy: 0.2768 - val_loss: 1.4202 - val_accuracy: 0.1502
Epoch 9/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3880 - accuracy: 0.3125 960/1008 [===========================>..] - ETA: 0s - loss: 1.3759 - accuracy: 0.2958
Epoch 00009: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 85us/sample - loss: 1.3747 - accuracy: 0.2986 - val_loss: 1.4184 - val_accuracy: 0.1561
Epoch 10/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4231 - accuracy: 0.2031 960/1008 [===========================>..] - ETA: 0s - loss: 1.3736 - accuracy: 0.2917
Epoch 00010: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 80us/sample - loss: 1.3753 - accuracy: 0.2857 - val_loss: 1.4144 - val_accuracy: 0.1917
Epoch 11/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3645 - accuracy: 0.2969
Epoch 00011: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 71us/sample - loss: 1.3663 - accuracy: 0.3145 - val_loss: 1.4099 - val_accuracy: 0.2213
Epoch 12/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3874 - accuracy: 0.2500
Epoch 00012: val_loss did not improve from 1.40047
1008/1008 [==============================] - 0s 71us/sample - loss: 1.3629 - accuracy: 0.3204 - val_loss: 1.4055 - val_accuracy: 0.2549
Epoch 13/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3888 - accuracy: 0.2656
Epoch 00013: val_loss improved from 1.40047 to 1.40021, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3630 - accuracy: 0.3165 - val_loss: 1.4002 - val_accuracy: 0.2747
Epoch 14/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3712 - accuracy: 0.2656
Epoch 00014: val_loss improved from 1.40021 to 1.39793, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3602 - accuracy: 0.3204 - val_loss: 1.3979 - val_accuracy: 0.2767
Epoch 15/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3957 - accuracy: 0.2344
Epoch 00015: val_loss improved from 1.39793 to 1.39381, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3635 - accuracy: 0.3135 - val_loss: 1.3938 - val_accuracy: 0.2866
Epoch 16/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3618 - accuracy: 0.2969
Epoch 00016: val_loss improved from 1.39381 to 1.38880, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.3487 - accuracy: 0.3274 - val_loss: 1.3888 - val_accuracy: 0.2866
Epoch 17/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3565 - accuracy: 0.2969
Epoch 00017: val_loss improved from 1.38880 to 1.38386, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.3500 - accuracy: 0.3363 - val_loss: 1.3839 - val_accuracy: 0.2846
Epoch 18/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3940 - accuracy: 0.2812
Epoch 00018: val_loss improved from 1.38386 to 1.37629, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 86us/sample - loss: 1.3452 - accuracy: 0.3562 - val_loss: 1.3763 - val_accuracy: 0.2925
Epoch 19/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2981 - accuracy: 0.4375
Epoch 00019: val_loss improved from 1.37629 to 1.36943, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.3452 - accuracy: 0.3492 - val_loss: 1.3694 - val_accuracy: 0.3004
Epoch 20/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2894 - accuracy: 0.5000
Epoch 00020: val_loss improved from 1.36943 to 1.36940, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3368 - accuracy: 0.3502 - val_loss: 1.3694 - val_accuracy: 0.2905
Epoch 21/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2563 - accuracy: 0.4688
Epoch 00021: val_loss improved from 1.36940 to 1.36855, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3263 - accuracy: 0.3661 - val_loss: 1.3685 - val_accuracy: 0.2964
Epoch 22/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3431 - accuracy: 0.3281
Epoch 00022: val_loss did not improve from 1.36855
1008/1008 [==============================] - 0s 70us/sample - loss: 1.3302 - accuracy: 0.3661 - val_loss: 1.3712 - val_accuracy: 0.2984
Epoch 23/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3279 - accuracy: 0.3594
Epoch 00023: val_loss did not improve from 1.36855
1008/1008 [==============================] - 0s 70us/sample - loss: 1.3305 - accuracy: 0.3581 - val_loss: 1.3746 - val_accuracy: 0.3024
Epoch 24/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3350 - accuracy: 0.2969
Epoch 00024: val_loss did not improve from 1.36855
1008/1008 [==============================] - 0s 70us/sample - loss: 1.3165 - accuracy: 0.3889 - val_loss: 1.3699 - val_accuracy: 0.3024
Epoch 25/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2782 - accuracy: 0.3906
Epoch 00025: val_loss improved from 1.36855 to 1.36228, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.3214 - accuracy: 0.3849 - val_loss: 1.3623 - val_accuracy: 0.3261
Epoch 26/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3449 - accuracy: 0.3906
Epoch 00026: val_loss did not improve from 1.36228
1008/1008 [==============================] - 0s 70us/sample - loss: 1.3292 - accuracy: 0.3730 - val_loss: 1.3646 - val_accuracy: 0.3340
Epoch 27/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3407 - accuracy: 0.3594
Epoch 00027: val_loss improved from 1.36228 to 1.36043, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3220 - accuracy: 0.3929 - val_loss: 1.3604 - val_accuracy: 0.3518
Epoch 28/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2688 - accuracy: 0.4688
Epoch 00028: val_loss improved from 1.36043 to 1.35093, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.3106 - accuracy: 0.3988 - val_loss: 1.3509 - val_accuracy: 0.3735
Epoch 29/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2892 - accuracy: 0.3906
Epoch 00029: val_loss improved from 1.35093 to 1.34664, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3087 - accuracy: 0.4087 - val_loss: 1.3466 - val_accuracy: 0.3834
Epoch 30/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3017 - accuracy: 0.3750
Epoch 00030: val_loss did not improve from 1.34664
1008/1008 [==============================] - 0s 71us/sample - loss: 1.3040 - accuracy: 0.4077 - val_loss: 1.3480 - val_accuracy: 0.3814
Epoch 31/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3181 - accuracy: 0.3594
Epoch 00031: val_loss improved from 1.34664 to 1.34235, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3106 - accuracy: 0.3929 - val_loss: 1.3423 - val_accuracy: 0.3933
Epoch 32/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3166 - accuracy: 0.4062
Epoch 00032: val_loss improved from 1.34235 to 1.33908, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3054 - accuracy: 0.4177 - val_loss: 1.3391 - val_accuracy: 0.3972
Epoch 33/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2547 - accuracy: 0.4531
Epoch 00033: val_loss improved from 1.33908 to 1.33580, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3100 - accuracy: 0.3998 - val_loss: 1.3358 - val_accuracy: 0.4032
Epoch 34/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3041 - accuracy: 0.4062
Epoch 00034: val_loss improved from 1.33580 to 1.33500, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3011 - accuracy: 0.4067 - val_loss: 1.3350 - val_accuracy: 0.3794
Epoch 35/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3558 - accuracy: 0.2969
Epoch 00035: val_loss improved from 1.33500 to 1.32100, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3013 - accuracy: 0.4018 - val_loss: 1.3210 - val_accuracy: 0.4209
Epoch 36/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3185 - accuracy: 0.4531
Epoch 00036: val_loss improved from 1.32100 to 1.32091, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.2952 - accuracy: 0.4315 - val_loss: 1.3209 - val_accuracy: 0.4209
Epoch 37/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2807 - accuracy: 0.4844
Epoch 00037: val_loss improved from 1.32091 to 1.31981, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3082 - accuracy: 0.3998 - val_loss: 1.3198 - val_accuracy: 0.4269
Epoch 38/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3308 - accuracy: 0.4062
Epoch 00038: val_loss improved from 1.31981 to 1.31305, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3061 - accuracy: 0.4117 - val_loss: 1.3130 - val_accuracy: 0.4486
Epoch 39/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3096 - accuracy: 0.4219
Epoch 00039: val_loss improved from 1.31305 to 1.31101, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 86us/sample - loss: 1.2916 - accuracy: 0.4296 - val_loss: 1.3110 - val_accuracy: 0.4427
Epoch 40/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3120 - accuracy: 0.4219
Epoch 00040: val_loss improved from 1.31101 to 1.30974, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 86us/sample - loss: 1.2957 - accuracy: 0.4266 - val_loss: 1.3097 - val_accuracy: 0.4308
Epoch 41/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2806 - accuracy: 0.4219
Epoch 00041: val_loss improved from 1.30974 to 1.30506, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2980 - accuracy: 0.4147 - val_loss: 1.3051 - val_accuracy: 0.4545
Epoch 42/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2908 - accuracy: 0.3906
Epoch 00042: val_loss improved from 1.30506 to 1.29370, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2923 - accuracy: 0.4206 - val_loss: 1.2937 - val_accuracy: 0.4545
Epoch 43/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2817 - accuracy: 0.4531
Epoch 00043: val_loss improved from 1.29370 to 1.29202, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2793 - accuracy: 0.4355 - val_loss: 1.2920 - val_accuracy: 0.4644
Epoch 44/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2931 - accuracy: 0.4062
Epoch 00044: val_loss improved from 1.29202 to 1.29090, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2870 - accuracy: 0.4365 - val_loss: 1.2909 - val_accuracy: 0.4644
Epoch 45/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3140 - accuracy: 0.4219
Epoch 00045: val_loss improved from 1.29090 to 1.28626, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2704 - accuracy: 0.4623 - val_loss: 1.2863 - val_accuracy: 0.4704
Epoch 46/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2540 - accuracy: 0.5000
Epoch 00046: val_loss did not improve from 1.28626
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2632 - accuracy: 0.4633 - val_loss: 1.2896 - val_accuracy: 0.4526
Epoch 47/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2207 - accuracy: 0.4688
Epoch 00047: val_loss did not improve from 1.28626
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2751 - accuracy: 0.4454 - val_loss: 1.2985 - val_accuracy: 0.4348
Epoch 48/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2666 - accuracy: 0.4531
Epoch 00048: val_loss did not improve from 1.28626
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2680 - accuracy: 0.4514 - val_loss: 1.2927 - val_accuracy: 0.4427
Epoch 49/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3264 - accuracy: 0.3125
Epoch 00049: val_loss did not improve from 1.28626
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2677 - accuracy: 0.4534 - val_loss: 1.2892 - val_accuracy: 0.4427
Epoch 50/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2374 - accuracy: 0.4844 960/1008 [===========================>..] - ETA: 0s - loss: 1.2729 - accuracy: 0.4437
Epoch 00050: val_loss did not improve from 1.28626
1008/1008 [==============================] - 0s 79us/sample - loss: 1.2722 - accuracy: 0.4435 - val_loss: 1.2936 - val_accuracy: 0.4368
Epoch 51/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3086 - accuracy: 0.4844
Epoch 00051: val_loss improved from 1.28626 to 1.28092, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2788 - accuracy: 0.4395 - val_loss: 1.2809 - val_accuracy: 0.4466
Epoch 52/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2696 - accuracy: 0.4219
Epoch 00052: val_loss improved from 1.28092 to 1.26657, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2600 - accuracy: 0.4752 - val_loss: 1.2666 - val_accuracy: 0.4822
Epoch 53/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2555 - accuracy: 0.4531
Epoch 00053: val_loss did not improve from 1.26657
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2543 - accuracy: 0.4742 - val_loss: 1.2694 - val_accuracy: 0.4783
Epoch 54/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2978 - accuracy: 0.4219
Epoch 00054: val_loss did not improve from 1.26657
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2526 - accuracy: 0.4702 - val_loss: 1.2675 - val_accuracy: 0.4842
Epoch 55/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2685 - accuracy: 0.4531
Epoch 00055: val_loss did not improve from 1.26657
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2475 - accuracy: 0.4841 - val_loss: 1.2735 - val_accuracy: 0.4862
Epoch 56/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2815 - accuracy: 0.4531
Epoch 00056: val_loss improved from 1.26657 to 1.26523, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 81us/sample - loss: 1.2524 - accuracy: 0.4881 - val_loss: 1.2652 - val_accuracy: 0.4822
Epoch 57/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2477 - accuracy: 0.5156
Epoch 00057: val_loss did not improve from 1.26523
1008/1008 [==============================] - 0s 73us/sample - loss: 1.2527 - accuracy: 0.4673 - val_loss: 1.2698 - val_accuracy: 0.4802
Epoch 58/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2647 - accuracy: 0.4688
Epoch 00058: val_loss improved from 1.26523 to 1.26489, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2436 - accuracy: 0.4851 - val_loss: 1.2649 - val_accuracy: 0.4862
Epoch 59/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3026 - accuracy: 0.4062
Epoch 00059: val_loss improved from 1.26489 to 1.25643, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.2646 - accuracy: 0.4623 - val_loss: 1.2564 - val_accuracy: 0.4901
Epoch 60/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2301 - accuracy: 0.5312
Epoch 00060: val_loss did not improve from 1.25643
1008/1008 [==============================] - 0s 72us/sample - loss: 1.2487 - accuracy: 0.4821 - val_loss: 1.2566 - val_accuracy: 0.4980
Epoch 61/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2123 - accuracy: 0.5312
Epoch 00061: val_loss did not improve from 1.25643
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2406 - accuracy: 0.4960 - val_loss: 1.2607 - val_accuracy: 0.4723
Epoch 62/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2611 - accuracy: 0.4531
Epoch 00062: val_loss did not improve from 1.25643
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2375 - accuracy: 0.4980 - val_loss: 1.2648 - val_accuracy: 0.4743
Epoch 63/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2868 - accuracy: 0.4531
Epoch 00063: val_loss did not improve from 1.25643
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2353 - accuracy: 0.5069 - val_loss: 1.2698 - val_accuracy: 0.4822
Epoch 64/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1700 - accuracy: 0.5938
Epoch 00064: val_loss did not improve from 1.25643
1008/1008 [==============================] - 0s 69us/sample - loss: 1.2289 - accuracy: 0.5060 - val_loss: 1.2592 - val_accuracy: 0.4842
Epoch 65/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1725 - accuracy: 0.5469
Epoch 00065: val_loss improved from 1.25643 to 1.23278, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2328 - accuracy: 0.5109 - val_loss: 1.2328 - val_accuracy: 0.5138
Epoch 66/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2327 - accuracy: 0.4844
Epoch 00066: val_loss improved from 1.23278 to 1.22990, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2271 - accuracy: 0.5119 - val_loss: 1.2299 - val_accuracy: 0.5138
Epoch 67/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1919 - accuracy: 0.5781
Epoch 00067: val_loss did not improve from 1.22990
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2285 - accuracy: 0.5109 - val_loss: 1.2361 - val_accuracy: 0.5119
Epoch 68/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2447 - accuracy: 0.4375
Epoch 00068: val_loss did not improve from 1.22990
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2199 - accuracy: 0.5159 - val_loss: 1.2493 - val_accuracy: 0.5040
Epoch 69/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2079 - accuracy: 0.5938
Epoch 00069: val_loss did not improve from 1.22990
1008/1008 [==============================] - 0s 73us/sample - loss: 1.2419 - accuracy: 0.4911 - val_loss: 1.2409 - val_accuracy: 0.5020
Epoch 70/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2914 - accuracy: 0.4062
Epoch 00070: val_loss did not improve from 1.22990
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2252 - accuracy: 0.5188 - val_loss: 1.2306 - val_accuracy: 0.5119
Epoch 71/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2300 - accuracy: 0.5000
Epoch 00071: val_loss improved from 1.22990 to 1.22421, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2354 - accuracy: 0.5129 - val_loss: 1.2242 - val_accuracy: 0.5257
Epoch 72/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2640 - accuracy: 0.4219
Epoch 00072: val_loss improved from 1.22421 to 1.22242, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2206 - accuracy: 0.5079 - val_loss: 1.2224 - val_accuracy: 0.5138
Epoch 73/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1421 - accuracy: 0.6719
Epoch 00073: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 72us/sample - loss: 1.2101 - accuracy: 0.5585 - val_loss: 1.2252 - val_accuracy: 0.5119
Epoch 74/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2244 - accuracy: 0.5312
Epoch 00074: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2269 - accuracy: 0.4990 - val_loss: 1.2291 - val_accuracy: 0.5158
Epoch 75/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1353 - accuracy: 0.5938
Epoch 00075: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 87us/sample - loss: 1.2144 - accuracy: 0.5149 - val_loss: 1.2346 - val_accuracy: 0.5119
Epoch 76/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1893 - accuracy: 0.5781 832/1008 [=======================>......] - ETA: 0s - loss: 1.2187 - accuracy: 0.5361
Epoch 00076: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 90us/sample - loss: 1.2158 - accuracy: 0.5397 - val_loss: 1.2383 - val_accuracy: 0.5099
Epoch 77/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2494 - accuracy: 0.4844
Epoch 00077: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 81us/sample - loss: 1.2076 - accuracy: 0.5476 - val_loss: 1.2415 - val_accuracy: 0.5178
Epoch 78/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1886 - accuracy: 0.5625
Epoch 00078: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 72us/sample - loss: 1.2122 - accuracy: 0.5308 - val_loss: 1.2313 - val_accuracy: 0.5119
Epoch 79/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2047 - accuracy: 0.5000
Epoch 00079: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2128 - accuracy: 0.5238 - val_loss: 1.2311 - val_accuracy: 0.5059
Epoch 80/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1419 - accuracy: 0.6719
Epoch 00080: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2038 - accuracy: 0.5486 - val_loss: 1.2419 - val_accuracy: 0.5000
Epoch 81/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2460 - accuracy: 0.4688
Epoch 00081: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1937 - accuracy: 0.5446 - val_loss: 1.2351 - val_accuracy: 0.5099
Epoch 82/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1448 - accuracy: 0.6406
Epoch 00082: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1977 - accuracy: 0.5476 - val_loss: 1.2304 - val_accuracy: 0.5079
Epoch 83/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1863 - accuracy: 0.5312 832/1008 [=======================>......] - ETA: 0s - loss: 1.1997 - accuracy: 0.5529
Epoch 00083: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 108us/sample - loss: 1.1986 - accuracy: 0.5516 - val_loss: 1.2342 - val_accuracy: 0.5178
Epoch 84/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1911 - accuracy: 0.5469
Epoch 00084: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 77us/sample - loss: 1.2019 - accuracy: 0.5347 - val_loss: 1.2366 - val_accuracy: 0.5158
Epoch 85/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1799 - accuracy: 0.5312
Epoch 00085: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1931 - accuracy: 0.5565 - val_loss: 1.2372 - val_accuracy: 0.5079
Epoch 86/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2333 - accuracy: 0.5000
Epoch 00086: val_loss did not improve from 1.22242
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1797 - accuracy: 0.5784 - val_loss: 1.2308 - val_accuracy: 0.5178
Epoch 87/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1877 - accuracy: 0.5625
Epoch 00087: val_loss improved from 1.22242 to 1.21393, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1928 - accuracy: 0.5466 - val_loss: 1.2139 - val_accuracy: 0.5435
Epoch 88/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2412 - accuracy: 0.5000
Epoch 00088: val_loss did not improve from 1.21393
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1910 - accuracy: 0.5605 - val_loss: 1.2270 - val_accuracy: 0.5217
Epoch 89/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2000 - accuracy: 0.5000
Epoch 00089: val_loss did not improve from 1.21393
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1934 - accuracy: 0.5506 - val_loss: 1.2265 - val_accuracy: 0.5178
Epoch 90/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1507 - accuracy: 0.5625 832/1008 [=======================>......] - ETA: 0s - loss: 1.1874 - accuracy: 0.5409
Epoch 00090: val_loss improved from 1.21393 to 1.21379, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 112us/sample - loss: 1.1917 - accuracy: 0.5397 - val_loss: 1.2138 - val_accuracy: 0.5395
Epoch 91/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1489 - accuracy: 0.6094 640/1008 [==================>...........] - ETA: 0s - loss: 1.1811 - accuracy: 0.5500
Epoch 00091: val_loss did not improve from 1.21379
1008/1008 [==============================] - 0s 121us/sample - loss: 1.1744 - accuracy: 0.5635 - val_loss: 1.2193 - val_accuracy: 0.5336
Epoch 92/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2450 - accuracy: 0.4688 960/1008 [===========================>..] - ETA: 0s - loss: 1.1888 - accuracy: 0.5542
Epoch 00092: val_loss did not improve from 1.21379
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1898 - accuracy: 0.5556 - val_loss: 1.2169 - val_accuracy: 0.5395
Epoch 93/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2114 - accuracy: 0.5625 960/1008 [===========================>..] - ETA: 0s - loss: 1.1832 - accuracy: 0.5583
Epoch 00093: val_loss did not improve from 1.21379
1008/1008 [==============================] - 0s 90us/sample - loss: 1.1849 - accuracy: 0.5575 - val_loss: 1.2187 - val_accuracy: 0.5415
Epoch 94/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1982 - accuracy: 0.5625 960/1008 [===========================>..] - ETA: 0s - loss: 1.1617 - accuracy: 0.5948
Epoch 00094: val_loss did not improve from 1.21379
1008/1008 [==============================] - 0s 91us/sample - loss: 1.1613 - accuracy: 0.5952 - val_loss: 1.2268 - val_accuracy: 0.5237
Epoch 95/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1752 - accuracy: 0.6094 640/1008 [==================>...........] - ETA: 0s - loss: 1.1577 - accuracy: 0.5859
Epoch 00095: val_loss did not improve from 1.21379
1008/1008 [==============================] - 0s 96us/sample - loss: 1.1563 - accuracy: 0.5933 - val_loss: 1.2319 - val_accuracy: 0.5158
Epoch 96/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1574 - accuracy: 0.5938
Epoch 00096: val_loss did not improve from 1.21379
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1704 - accuracy: 0.5744 - val_loss: 1.2280 - val_accuracy: 0.5079
Epoch 97/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2271 - accuracy: 0.5312
Epoch 00097: val_loss did not improve from 1.21379
1008/1008 [==============================] - 0s 69us/sample - loss: 1.1678 - accuracy: 0.5933 - val_loss: 1.2180 - val_accuracy: 0.5277
Epoch 98/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1233 - accuracy: 0.6094
Epoch 00098: val_loss improved from 1.21379 to 1.21100, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 113us/sample - loss: 1.1717 - accuracy: 0.5734 - val_loss: 1.2110 - val_accuracy: 0.5277
Epoch 99/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1612 - accuracy: 0.5938 896/1008 [=========================>....] - ETA: 0s - loss: 1.1546 - accuracy: 0.5859
Epoch 00099: val_loss did not improve from 1.21100
1008/1008 [==============================] - 0s 86us/sample - loss: 1.1546 - accuracy: 0.5833 - val_loss: 1.2135 - val_accuracy: 0.5138
Epoch 100/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0739 - accuracy: 0.7656 960/1008 [===========================>..] - ETA: 0s - loss: 1.1549 - accuracy: 0.6031
Epoch 00100: val_loss did not improve from 1.21100
1008/1008 [==============================] - 0s 80us/sample - loss: 1.1549 - accuracy: 0.6022 - val_loss: 1.2194 - val_accuracy: 0.5178
Epoch 101/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1669 - accuracy: 0.5312
Epoch 00101: val_loss did not improve from 1.21100
1008/1008 [==============================] - 0s 80us/sample - loss: 1.1672 - accuracy: 0.5774 - val_loss: 1.2133 - val_accuracy: 0.5356
Epoch 102/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2010 - accuracy: 0.6094 960/1008 [===========================>..] - ETA: 0s - loss: 1.1708 - accuracy: 0.5750
Epoch 00102: val_loss improved from 1.21100 to 1.21072, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 102us/sample - loss: 1.1658 - accuracy: 0.5804 - val_loss: 1.2107 - val_accuracy: 0.5395
Epoch 103/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0616 - accuracy: 0.7344 960/1008 [===========================>..] - ETA: 0s - loss: 1.1510 - accuracy: 0.5969
Epoch 00103: val_loss improved from 1.21072 to 1.20826, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 93us/sample - loss: 1.1495 - accuracy: 0.5982 - val_loss: 1.2083 - val_accuracy: 0.5296
Epoch 104/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0668 - accuracy: 0.6719
Epoch 00104: val_loss improved from 1.20826 to 1.20107, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1551 - accuracy: 0.6012 - val_loss: 1.2011 - val_accuracy: 0.5435
Epoch 105/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1748 - accuracy: 0.5625
Epoch 00105: val_loss improved from 1.20107 to 1.19679, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1635 - accuracy: 0.5933 - val_loss: 1.1968 - val_accuracy: 0.5455
Epoch 106/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1726 - accuracy: 0.6094
Epoch 00106: val_loss did not improve from 1.19679
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1536 - accuracy: 0.5933 - val_loss: 1.2093 - val_accuracy: 0.5375
Epoch 107/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2281 - accuracy: 0.5312
Epoch 00107: val_loss did not improve from 1.19679
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1595 - accuracy: 0.5982 - val_loss: 1.2099 - val_accuracy: 0.5356
Epoch 108/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1421 - accuracy: 0.6094
Epoch 00108: val_loss did not improve from 1.19679
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1524 - accuracy: 0.6002 - val_loss: 1.2224 - val_accuracy: 0.5138
Epoch 109/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1221 - accuracy: 0.6562
Epoch 00109: val_loss did not improve from 1.19679
1008/1008 [==============================] - 0s 79us/sample - loss: 1.1495 - accuracy: 0.6071 - val_loss: 1.2264 - val_accuracy: 0.5099
Epoch 110/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0916 - accuracy: 0.6562 960/1008 [===========================>..] - ETA: 0s - loss: 1.1549 - accuracy: 0.5844
Epoch 00110: val_loss did not improve from 1.19679
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1510 - accuracy: 0.5893 - val_loss: 1.2063 - val_accuracy: 0.5455
Epoch 111/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1931 - accuracy: 0.5469 960/1008 [===========================>..] - ETA: 0s - loss: 1.1364 - accuracy: 0.6250
Epoch 00111: val_loss did not improve from 1.19679
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1369 - accuracy: 0.6230 - val_loss: 1.2043 - val_accuracy: 0.5435
Epoch 112/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0760 - accuracy: 0.6719 768/1008 [=====================>........] - ETA: 0s - loss: 1.1424 - accuracy: 0.6055
Epoch 00112: val_loss did not improve from 1.19679
1008/1008 [==============================] - 0s 93us/sample - loss: 1.1469 - accuracy: 0.6042 - val_loss: 1.2082 - val_accuracy: 0.5316
Epoch 113/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1376 - accuracy: 0.6406
Epoch 00113: val_loss improved from 1.19679 to 1.19332, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1336 - accuracy: 0.6200 - val_loss: 1.1933 - val_accuracy: 0.5474
Epoch 114/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1539 - accuracy: 0.5938 768/1008 [=====================>........] - ETA: 0s - loss: 1.1413 - accuracy: 0.6146
Epoch 00114: val_loss did not improve from 1.19332
1008/1008 [==============================] - 0s 106us/sample - loss: 1.1306 - accuracy: 0.6200 - val_loss: 1.2016 - val_accuracy: 0.5316
Epoch 115/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1427 - accuracy: 0.6406 832/1008 [=======================>......] - ETA: 0s - loss: 1.1349 - accuracy: 0.6046
Epoch 00115: val_loss did not improve from 1.19332
1008/1008 [==============================] - 0s 96us/sample - loss: 1.1409 - accuracy: 0.5992 - val_loss: 1.2072 - val_accuracy: 0.5375
Epoch 116/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1655 - accuracy: 0.6250 832/1008 [=======================>......] - ETA: 0s - loss: 1.1323 - accuracy: 0.6286
Epoch 00116: val_loss improved from 1.19332 to 1.19257, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 99us/sample - loss: 1.1375 - accuracy: 0.6161 - val_loss: 1.1926 - val_accuracy: 0.5494
Epoch 117/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2191 - accuracy: 0.5312 960/1008 [===========================>..] - ETA: 0s - loss: 1.1268 - accuracy: 0.6365
Epoch 00117: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 94us/sample - loss: 1.1268 - accuracy: 0.6349 - val_loss: 1.2076 - val_accuracy: 0.5316
Epoch 118/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1222 - accuracy: 0.6562 896/1008 [=========================>....] - ETA: 0s - loss: 1.1354 - accuracy: 0.6183
Epoch 00118: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 91us/sample - loss: 1.1339 - accuracy: 0.6200 - val_loss: 1.2119 - val_accuracy: 0.5277
Epoch 119/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1414 - accuracy: 0.6094 832/1008 [=======================>......] - ETA: 0s - loss: 1.1364 - accuracy: 0.6058
Epoch 00119: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 99us/sample - loss: 1.1322 - accuracy: 0.6091 - val_loss: 1.2104 - val_accuracy: 0.5395
Epoch 120/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1102 - accuracy: 0.6875 896/1008 [=========================>....] - ETA: 0s - loss: 1.1212 - accuracy: 0.6283
Epoch 00120: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 88us/sample - loss: 1.1268 - accuracy: 0.6171 - val_loss: 1.2080 - val_accuracy: 0.5395
Epoch 121/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0606 - accuracy: 0.7031
Epoch 00121: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 79us/sample - loss: 1.1221 - accuracy: 0.6230 - val_loss: 1.1960 - val_accuracy: 0.5494
Epoch 122/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1206 - accuracy: 0.6094 960/1008 [===========================>..] - ETA: 0s - loss: 1.1209 - accuracy: 0.6219
Epoch 00122: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 81us/sample - loss: 1.1210 - accuracy: 0.6220 - val_loss: 1.2006 - val_accuracy: 0.5534
Epoch 123/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1782 - accuracy: 0.5312 960/1008 [===========================>..] - ETA: 0s - loss: 1.1197 - accuracy: 0.6302
Epoch 00123: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 98us/sample - loss: 1.1214 - accuracy: 0.6280 - val_loss: 1.1999 - val_accuracy: 0.5395
Epoch 124/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0874 - accuracy: 0.6562 960/1008 [===========================>..] - ETA: 0s - loss: 1.1186 - accuracy: 0.6333
Epoch 00124: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1183 - accuracy: 0.6319 - val_loss: 1.2051 - val_accuracy: 0.5375
Epoch 125/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1360 - accuracy: 0.6250 960/1008 [===========================>..] - ETA: 0s - loss: 1.1157 - accuracy: 0.6479
Epoch 00125: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 95us/sample - loss: 1.1150 - accuracy: 0.6478 - val_loss: 1.1981 - val_accuracy: 0.5494
Epoch 126/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1149 - accuracy: 0.6875
Epoch 00126: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 74us/sample - loss: 1.1191 - accuracy: 0.6349 - val_loss: 1.2255 - val_accuracy: 0.5217
Epoch 127/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1482 - accuracy: 0.5625
Epoch 00127: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1226 - accuracy: 0.6300 - val_loss: 1.2308 - val_accuracy: 0.5158
Epoch 128/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2198 - accuracy: 0.5156
Epoch 00128: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1244 - accuracy: 0.6270 - val_loss: 1.2247 - val_accuracy: 0.5158
Epoch 129/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1045 - accuracy: 0.6875
Epoch 00129: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1085 - accuracy: 0.6468 - val_loss: 1.2281 - val_accuracy: 0.5059
Epoch 130/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1066 - accuracy: 0.5625 960/1008 [===========================>..] - ETA: 0s - loss: 1.1072 - accuracy: 0.6448
Epoch 00130: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 80us/sample - loss: 1.1059 - accuracy: 0.6488 - val_loss: 1.2376 - val_accuracy: 0.4881
Epoch 131/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0476 - accuracy: 0.7188 960/1008 [===========================>..] - ETA: 0s - loss: 1.1053 - accuracy: 0.6479
Epoch 00131: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1037 - accuracy: 0.6488 - val_loss: 1.2301 - val_accuracy: 0.5138
Epoch 132/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1967 - accuracy: 0.5156 960/1008 [===========================>..] - ETA: 0s - loss: 1.1059 - accuracy: 0.6521
Epoch 00132: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1046 - accuracy: 0.6538 - val_loss: 1.2370 - val_accuracy: 0.4980
Epoch 133/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0978 - accuracy: 0.6719 960/1008 [===========================>..] - ETA: 0s - loss: 1.0964 - accuracy: 0.6729
Epoch 00133: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0955 - accuracy: 0.6716 - val_loss: 1.2279 - val_accuracy: 0.5099
Epoch 134/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1262 - accuracy: 0.5938
Epoch 00134: val_loss did not improve from 1.19257
1008/1008 [==============================] - 0s 74us/sample - loss: 1.0965 - accuracy: 0.6548 - val_loss: 1.2321 - val_accuracy: 0.5000
Epoch 135/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0872 - accuracy: 0.6875
Epoch 00135: val_loss improved from 1.19257 to 1.18731, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1037 - accuracy: 0.6518 - val_loss: 1.1873 - val_accuracy: 0.5455
Epoch 136/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1273 - accuracy: 0.6094
Epoch 00136: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1026 - accuracy: 0.6488 - val_loss: 1.2348 - val_accuracy: 0.4901
Epoch 137/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0958 - accuracy: 0.6875
Epoch 00137: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0982 - accuracy: 0.6667 - val_loss: 1.1982 - val_accuracy: 0.5257
Epoch 138/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1477 - accuracy: 0.6250
Epoch 00138: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1075 - accuracy: 0.6448 - val_loss: 1.1909 - val_accuracy: 0.5514
Epoch 139/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1057 - accuracy: 0.6562
Epoch 00139: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0883 - accuracy: 0.6647 - val_loss: 1.2139 - val_accuracy: 0.5474
Epoch 140/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0511 - accuracy: 0.6875
Epoch 00140: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0878 - accuracy: 0.6607 - val_loss: 1.1929 - val_accuracy: 0.5474
Epoch 141/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0702 - accuracy: 0.6875
Epoch 00141: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0781 - accuracy: 0.6716 - val_loss: 1.1899 - val_accuracy: 0.5534
Epoch 142/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0822 - accuracy: 0.6562
Epoch 00142: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 75us/sample - loss: 1.0851 - accuracy: 0.6647 - val_loss: 1.1954 - val_accuracy: 0.5514
Epoch 143/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0547 - accuracy: 0.7344 960/1008 [===========================>..] - ETA: 0s - loss: 1.0987 - accuracy: 0.6427
Epoch 00143: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0991 - accuracy: 0.6438 - val_loss: 1.1985 - val_accuracy: 0.5494
Epoch 144/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1079 - accuracy: 0.5938 960/1008 [===========================>..] - ETA: 0s - loss: 1.0805 - accuracy: 0.6542
Epoch 00144: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0786 - accuracy: 0.6577 - val_loss: 1.2114 - val_accuracy: 0.5277
Epoch 145/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0836 - accuracy: 0.6562 960/1008 [===========================>..] - ETA: 0s - loss: 1.0928 - accuracy: 0.6469
Epoch 00145: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 82us/sample - loss: 1.0938 - accuracy: 0.6458 - val_loss: 1.2059 - val_accuracy: 0.5316
Epoch 146/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0663 - accuracy: 0.7188
Epoch 00146: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0809 - accuracy: 0.6776 - val_loss: 1.2181 - val_accuracy: 0.5217
Epoch 147/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0755 - accuracy: 0.7188 896/1008 [=========================>....] - ETA: 0s - loss: 1.0810 - accuracy: 0.6842
Epoch 00147: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 100us/sample - loss: 1.0725 - accuracy: 0.6964 - val_loss: 1.1956 - val_accuracy: 0.5435
Epoch 148/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1307 - accuracy: 0.6094 896/1008 [=========================>....] - ETA: 0s - loss: 1.0819 - accuracy: 0.6708
Epoch 00148: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 87us/sample - loss: 1.0727 - accuracy: 0.6815 - val_loss: 1.2069 - val_accuracy: 0.5415
Epoch 149/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0586 - accuracy: 0.7031 960/1008 [===========================>..] - ETA: 0s - loss: 1.0721 - accuracy: 0.6823
Epoch 00149: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 82us/sample - loss: 1.0720 - accuracy: 0.6835 - val_loss: 1.1978 - val_accuracy: 0.5514
Epoch 150/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1317 - accuracy: 0.5781
Epoch 00150: val_loss did not improve from 1.18731
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0760 - accuracy: 0.6687 - val_loss: 1.1899 - val_accuracy: 0.5514
Epoch 151/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0694 - accuracy: 0.6719
Epoch 00151: val_loss improved from 1.18731 to 1.18340, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0817 - accuracy: 0.6696 - val_loss: 1.1834 - val_accuracy: 0.5474
Epoch 152/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0423 - accuracy: 0.7500
Epoch 00152: val_loss did not improve from 1.18340
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0658 - accuracy: 0.6835 - val_loss: 1.1984 - val_accuracy: 0.5435
Epoch 153/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1004 - accuracy: 0.6250
Epoch 00153: val_loss did not improve from 1.18340
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0729 - accuracy: 0.6796 - val_loss: 1.1858 - val_accuracy: 0.5553
Epoch 154/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0662 - accuracy: 0.7031
Epoch 00154: val_loss did not improve from 1.18340
1008/1008 [==============================] - 0s 69us/sample - loss: 1.0713 - accuracy: 0.6875 - val_loss: 1.1873 - val_accuracy: 0.5573
Epoch 155/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0518 - accuracy: 0.7188
Epoch 00155: val_loss did not improve from 1.18340
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0596 - accuracy: 0.6974 - val_loss: 1.1999 - val_accuracy: 0.5455
Epoch 156/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1218 - accuracy: 0.6250
Epoch 00156: val_loss did not improve from 1.18340
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0652 - accuracy: 0.6895 - val_loss: 1.2001 - val_accuracy: 0.5336
Epoch 157/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1039 - accuracy: 0.6250
Epoch 00157: val_loss did not improve from 1.18340
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0832 - accuracy: 0.6617 - val_loss: 1.2262 - val_accuracy: 0.5000
Epoch 158/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0485 - accuracy: 0.7031
Epoch 00158: val_loss did not improve from 1.18340
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0699 - accuracy: 0.6786 - val_loss: 1.2207 - val_accuracy: 0.5178
Epoch 159/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0976 - accuracy: 0.6562
Epoch 00159: val_loss did not improve from 1.18340
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0536 - accuracy: 0.7093 - val_loss: 1.1927 - val_accuracy: 0.5534
Epoch 160/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1032 - accuracy: 0.6250
Epoch 00160: val_loss improved from 1.18340 to 1.17640, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0698 - accuracy: 0.6825 - val_loss: 1.1764 - val_accuracy: 0.5692
Epoch 161/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0004 - accuracy: 0.7500
Epoch 00161: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 74us/sample - loss: 1.0619 - accuracy: 0.6935 - val_loss: 1.1783 - val_accuracy: 0.5573
Epoch 162/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1219 - accuracy: 0.6094 960/1008 [===========================>..] - ETA: 0s - loss: 1.0624 - accuracy: 0.6896
Epoch 00162: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 81us/sample - loss: 1.0639 - accuracy: 0.6895 - val_loss: 1.1843 - val_accuracy: 0.5573
Epoch 163/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0643 - accuracy: 0.6406 960/1008 [===========================>..] - ETA: 0s - loss: 1.0516 - accuracy: 0.7063
Epoch 00163: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0590 - accuracy: 0.6944 - val_loss: 1.1898 - val_accuracy: 0.5573
Epoch 164/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0735 - accuracy: 0.6406 960/1008 [===========================>..] - ETA: 0s - loss: 1.0627 - accuracy: 0.6875
Epoch 00164: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 81us/sample - loss: 1.0596 - accuracy: 0.6915 - val_loss: 1.1889 - val_accuracy: 0.5553
Epoch 165/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0679 - accuracy: 0.7188
Epoch 00165: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 82us/sample - loss: 1.0474 - accuracy: 0.7163 - val_loss: 1.2054 - val_accuracy: 0.5257
Epoch 166/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0912 - accuracy: 0.6250 960/1008 [===========================>..] - ETA: 0s - loss: 1.0508 - accuracy: 0.7010
Epoch 00166: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 84us/sample - loss: 1.0477 - accuracy: 0.7054 - val_loss: 1.1898 - val_accuracy: 0.5494
Epoch 167/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9454 - accuracy: 0.8594 960/1008 [===========================>..] - ETA: 0s - loss: 1.0529 - accuracy: 0.6979
Epoch 00167: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 85us/sample - loss: 1.0551 - accuracy: 0.6944 - val_loss: 1.1832 - val_accuracy: 0.5534
Epoch 168/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1391 - accuracy: 0.6406
Epoch 00168: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 77us/sample - loss: 1.0461 - accuracy: 0.7163 - val_loss: 1.1894 - val_accuracy: 0.5514
Epoch 169/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9785 - accuracy: 0.7969
Epoch 00169: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 74us/sample - loss: 1.0465 - accuracy: 0.6974 - val_loss: 1.2074 - val_accuracy: 0.5336
Epoch 170/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0548 - accuracy: 0.6719 960/1008 [===========================>..] - ETA: 0s - loss: 1.0372 - accuracy: 0.7219
Epoch 00170: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 95us/sample - loss: 1.0384 - accuracy: 0.7192 - val_loss: 1.1936 - val_accuracy: 0.5415
Epoch 171/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0350 - accuracy: 0.7031 960/1008 [===========================>..] - ETA: 0s - loss: 1.0393 - accuracy: 0.7219
Epoch 00171: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0380 - accuracy: 0.7222 - val_loss: 1.2182 - val_accuracy: 0.5178
Epoch 172/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0620 - accuracy: 0.6875 960/1008 [===========================>..] - ETA: 0s - loss: 1.0514 - accuracy: 0.6917
Epoch 00172: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 83us/sample - loss: 1.0560 - accuracy: 0.6875 - val_loss: 1.1951 - val_accuracy: 0.5494
Epoch 173/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0627 - accuracy: 0.6562 960/1008 [===========================>..] - ETA: 0s - loss: 1.0378 - accuracy: 0.7240
Epoch 00173: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 78us/sample - loss: 1.0394 - accuracy: 0.7212 - val_loss: 1.2110 - val_accuracy: 0.5277
Epoch 174/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0077 - accuracy: 0.7031
Epoch 00174: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0465 - accuracy: 0.6974 - val_loss: 1.2280 - val_accuracy: 0.5000
Epoch 175/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0390 - accuracy: 0.6875
Epoch 00175: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 77us/sample - loss: 1.0408 - accuracy: 0.7103 - val_loss: 1.1778 - val_accuracy: 0.5553
Epoch 176/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0554 - accuracy: 0.7188 960/1008 [===========================>..] - ETA: 0s - loss: 1.0444 - accuracy: 0.7115
Epoch 00176: val_loss did not improve from 1.17640
1008/1008 [==============================] - 0s 81us/sample - loss: 1.0444 - accuracy: 0.7143 - val_loss: 1.1813 - val_accuracy: 0.5534
Epoch 177/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0046 - accuracy: 0.7344 768/1008 [=====================>........] - ETA: 0s - loss: 1.0426 - accuracy: 0.7083
Epoch 00177: val_loss improved from 1.17640 to 1.17464, saving model to saved_models/TfidfTransformer_bestloss
1008/1008 [==============================] - 0s 106us/sample - loss: 1.0399 - accuracy: 0.7083 - val_loss: 1.1746 - val_accuracy: 0.5632
Epoch 178/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0508 - accuracy: 0.6875 960/1008 [===========================>..] - ETA: 0s - loss: 1.0329 - accuracy: 0.7208
Epoch 00178: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 85us/sample - loss: 1.0321 - accuracy: 0.7232 - val_loss: 1.1791 - val_accuracy: 0.5593
Epoch 179/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9953 - accuracy: 0.7656
Epoch 00179: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0260 - accuracy: 0.7361 - val_loss: 1.1846 - val_accuracy: 0.5494
Epoch 180/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0053 - accuracy: 0.7656
Epoch 00180: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0365 - accuracy: 0.7212 - val_loss: 1.1926 - val_accuracy: 0.5474
Epoch 181/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0031 - accuracy: 0.7500
Epoch 00181: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0338 - accuracy: 0.7173 - val_loss: 1.1785 - val_accuracy: 0.5573
Epoch 182/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0188 - accuracy: 0.7500
Epoch 00182: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0300 - accuracy: 0.7212 - val_loss: 1.1789 - val_accuracy: 0.5632
Epoch 183/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0178 - accuracy: 0.7969
Epoch 00183: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0290 - accuracy: 0.7321 - val_loss: 1.1849 - val_accuracy: 0.5435
Epoch 184/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9521 - accuracy: 0.8125
Epoch 00184: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0310 - accuracy: 0.7242 - val_loss: 1.1853 - val_accuracy: 0.5395
Epoch 185/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0880 - accuracy: 0.7188
Epoch 00185: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0402 - accuracy: 0.7083 - val_loss: 1.1970 - val_accuracy: 0.5375
Epoch 186/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0324 - accuracy: 0.7344
Epoch 00186: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0282 - accuracy: 0.7202 - val_loss: 1.1840 - val_accuracy: 0.5534
Epoch 187/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0609 - accuracy: 0.7031
Epoch 00187: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0233 - accuracy: 0.7272 - val_loss: 1.1939 - val_accuracy: 0.5514
Epoch 188/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0418 - accuracy: 0.7188
Epoch 00188: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0299 - accuracy: 0.7262 - val_loss: 1.1849 - val_accuracy: 0.5435
Epoch 189/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0729 - accuracy: 0.7188
Epoch 00189: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0297 - accuracy: 0.7212 - val_loss: 1.1880 - val_accuracy: 0.5455
Epoch 190/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0398 - accuracy: 0.6875
Epoch 00190: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0185 - accuracy: 0.7341 - val_loss: 1.2080 - val_accuracy: 0.5217
Epoch 191/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9957 - accuracy: 0.7500
Epoch 00191: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0241 - accuracy: 0.7302 - val_loss: 1.1841 - val_accuracy: 0.5494
Epoch 192/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0511 - accuracy: 0.7031
Epoch 00192: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0267 - accuracy: 0.7212 - val_loss: 1.2111 - val_accuracy: 0.5178
Epoch 193/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0411 - accuracy: 0.6875
Epoch 00193: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0308 - accuracy: 0.7212 - val_loss: 1.1944 - val_accuracy: 0.5296
Epoch 194/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9981 - accuracy: 0.7656
Epoch 00194: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0246 - accuracy: 0.7302 - val_loss: 1.1779 - val_accuracy: 0.5553
Epoch 195/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0664 - accuracy: 0.7031
Epoch 00195: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0353 - accuracy: 0.7242 - val_loss: 1.2054 - val_accuracy: 0.5178
Epoch 196/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0759 - accuracy: 0.6406 960/1008 [===========================>..] - ETA: 0s - loss: 1.0323 - accuracy: 0.7115
Epoch 00196: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 80us/sample - loss: 1.0314 - accuracy: 0.7143 - val_loss: 1.2184 - val_accuracy: 0.5040
Epoch 197/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0005 - accuracy: 0.7969
Epoch 00197: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0242 - accuracy: 0.7262 - val_loss: 1.2190 - val_accuracy: 0.4980
Epoch 198/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0240 - accuracy: 0.6875
Epoch 00198: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0129 - accuracy: 0.7440 - val_loss: 1.1998 - val_accuracy: 0.5138
Epoch 199/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0713 - accuracy: 0.6719
Epoch 00199: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 74us/sample - loss: 1.0220 - accuracy: 0.7421 - val_loss: 1.2019 - val_accuracy: 0.5119
Epoch 200/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9876 - accuracy: 0.7500
Epoch 00200: val_loss did not improve from 1.17464
1008/1008 [==============================] - 0s 68us/sample - loss: 1.0140 - accuracy: 0.7411 - val_loss: 1.2084 - val_accuracy: 0.4980

Results of vectorizer TfidfTransformer using a dnn:
acc   = 0.5632411067193676
macro = (0.3489143308330043, 0.3935226101045809, 0.36387020666144954, None)

Results of vectorizer TfidfVectorizer using a SVM with kernel type linear:
acc   = 0.567193675889328
macro = (0.4285684447326886, 0.3896152343624917, 0.3570172937144808, None)

Results of vectorizer TfidfVectorizer using a SVM with kernel type poly:
acc   = 0.49407114624505927
macro = (0.3087383897705027, 0.30428960309097297, 0.25359207678286627, None)

Results of vectorizer TfidfVectorizer using a SVM with kernel type rbf:
acc   = 0.5375494071146245
macro = (0.2894341290893015, 0.3455391640323147, 0.3006254225828262, None)

Results of vectorizer TfidfVectorizer using a SVM with kernel type sigmoid:
acc   = 0.4407114624505929
macro = (0.23812993482062425, 0.31265367053038284, 0.2529203956665097, None)
Train on 1008 samples, validate on 506 samples
Epoch 1/200
  64/1008 [>.............................] - ETA: 8s - loss: 1.3904 - accuracy: 0.2812
Epoch 00001: val_loss improved from inf to 1.39233, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 1s 761us/sample - loss: 1.3993 - accuracy: 0.2669 - val_loss: 1.3923 - val_accuracy: 0.1225
Epoch 2/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.4444 - accuracy: 0.2188
Epoch 00002: val_loss did not improve from 1.39233
1008/1008 [==============================] - 0s 70us/sample - loss: 1.4029 - accuracy: 0.2609 - val_loss: 1.3937 - val_accuracy: 0.1225
Epoch 3/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3382 - accuracy: 0.3594 896/1008 [=========================>....] - ETA: 0s - loss: 1.3709 - accuracy: 0.3092
Epoch 00003: val_loss did not improve from 1.39233
1008/1008 [==============================] - 0s 80us/sample - loss: 1.3707 - accuracy: 0.3085 - val_loss: 1.3931 - val_accuracy: 0.1206
Epoch 4/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3362 - accuracy: 0.4062
Epoch 00004: val_loss improved from 1.39233 to 1.39157, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3702 - accuracy: 0.2996 - val_loss: 1.3916 - val_accuracy: 0.0929
Epoch 5/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3344 - accuracy: 0.3125
Epoch 00005: val_loss improved from 1.39157 to 1.38825, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3574 - accuracy: 0.3333 - val_loss: 1.3882 - val_accuracy: 0.1324
Epoch 6/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2622 - accuracy: 0.4688
Epoch 00006: val_loss improved from 1.38825 to 1.38518, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3280 - accuracy: 0.3730 - val_loss: 1.3852 - val_accuracy: 0.2431
Epoch 7/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3424 - accuracy: 0.2969
Epoch 00007: val_loss improved from 1.38518 to 1.38217, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3605 - accuracy: 0.3274 - val_loss: 1.3822 - val_accuracy: 0.3518
Epoch 8/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3234 - accuracy: 0.4219
Epoch 00008: val_loss improved from 1.38217 to 1.37742, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3300 - accuracy: 0.3700 - val_loss: 1.3774 - val_accuracy: 0.4150
Epoch 9/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3021 - accuracy: 0.3594
Epoch 00009: val_loss improved from 1.37742 to 1.37188, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 86us/sample - loss: 1.3250 - accuracy: 0.3730 - val_loss: 1.3719 - val_accuracy: 0.4308
Epoch 10/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3599 - accuracy: 0.3125
Epoch 00010: val_loss improved from 1.37188 to 1.36617, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 86us/sample - loss: 1.3281 - accuracy: 0.3700 - val_loss: 1.3662 - val_accuracy: 0.4348
Epoch 11/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3311 - accuracy: 0.3906
Epoch 00011: val_loss improved from 1.36617 to 1.36115, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3298 - accuracy: 0.3661 - val_loss: 1.3611 - val_accuracy: 0.4269
Epoch 12/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3432 - accuracy: 0.3750
Epoch 00012: val_loss improved from 1.36115 to 1.35456, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3312 - accuracy: 0.3909 - val_loss: 1.3546 - val_accuracy: 0.4269
Epoch 13/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3456 - accuracy: 0.3594
Epoch 00013: val_loss improved from 1.35456 to 1.34987, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 87us/sample - loss: 1.3348 - accuracy: 0.3710 - val_loss: 1.3499 - val_accuracy: 0.4407
Epoch 14/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3230 - accuracy: 0.4219
Epoch 00014: val_loss improved from 1.34987 to 1.34387, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3222 - accuracy: 0.3849 - val_loss: 1.3439 - val_accuracy: 0.4585
Epoch 15/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3526 - accuracy: 0.3281
Epoch 00015: val_loss improved from 1.34387 to 1.33855, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.3190 - accuracy: 0.3859 - val_loss: 1.3385 - val_accuracy: 0.4704
Epoch 16/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2749 - accuracy: 0.4219
Epoch 00016: val_loss improved from 1.33855 to 1.33345, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3209 - accuracy: 0.3760 - val_loss: 1.3335 - val_accuracy: 0.4743
Epoch 17/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2780 - accuracy: 0.4062
Epoch 00017: val_loss improved from 1.33345 to 1.33031, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3170 - accuracy: 0.3988 - val_loss: 1.3303 - val_accuracy: 0.4822
Epoch 18/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2553 - accuracy: 0.4688
Epoch 00018: val_loss improved from 1.33031 to 1.32515, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.3044 - accuracy: 0.4167 - val_loss: 1.3251 - val_accuracy: 0.4921
Epoch 19/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2918 - accuracy: 0.4531
Epoch 00019: val_loss improved from 1.32515 to 1.31998, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.3035 - accuracy: 0.4087 - val_loss: 1.3200 - val_accuracy: 0.5138
Epoch 20/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2358 - accuracy: 0.4844
Epoch 00020: val_loss improved from 1.31998 to 1.31707, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.3033 - accuracy: 0.4147 - val_loss: 1.3171 - val_accuracy: 0.5257
Epoch 21/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3545 - accuracy: 0.3438
Epoch 00021: val_loss improved from 1.31707 to 1.31523, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 87us/sample - loss: 1.3053 - accuracy: 0.4187 - val_loss: 1.3152 - val_accuracy: 0.5119
Epoch 22/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3636 - accuracy: 0.3750
Epoch 00022: val_loss improved from 1.31523 to 1.31085, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.3046 - accuracy: 0.4206 - val_loss: 1.3108 - val_accuracy: 0.5138
Epoch 23/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2965 - accuracy: 0.4062
Epoch 00023: val_loss improved from 1.31085 to 1.30542, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2975 - accuracy: 0.4167 - val_loss: 1.3054 - val_accuracy: 0.5059
Epoch 24/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2402 - accuracy: 0.5000
Epoch 00024: val_loss improved from 1.30542 to 1.30147, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.2898 - accuracy: 0.4355 - val_loss: 1.3015 - val_accuracy: 0.4941
Epoch 25/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3322 - accuracy: 0.4062
Epoch 00025: val_loss improved from 1.30147 to 1.29589, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2944 - accuracy: 0.4236 - val_loss: 1.2959 - val_accuracy: 0.4881
Epoch 26/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3580 - accuracy: 0.3125
Epoch 00026: val_loss improved from 1.29589 to 1.29187, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2878 - accuracy: 0.4345 - val_loss: 1.2919 - val_accuracy: 0.4921
Epoch 27/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2403 - accuracy: 0.5156
Epoch 00027: val_loss improved from 1.29187 to 1.28900, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 87us/sample - loss: 1.2954 - accuracy: 0.4345 - val_loss: 1.2890 - val_accuracy: 0.4901
Epoch 28/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2642 - accuracy: 0.4531
Epoch 00028: val_loss improved from 1.28900 to 1.28535, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2815 - accuracy: 0.4385 - val_loss: 1.2853 - val_accuracy: 0.4881
Epoch 29/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2979 - accuracy: 0.4219
Epoch 00029: val_loss improved from 1.28535 to 1.27729, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2731 - accuracy: 0.4563 - val_loss: 1.2773 - val_accuracy: 0.4822
Epoch 30/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2771 - accuracy: 0.4844
Epoch 00030: val_loss improved from 1.27729 to 1.27253, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2817 - accuracy: 0.4385 - val_loss: 1.2725 - val_accuracy: 0.4842
Epoch 31/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2707 - accuracy: 0.4531
Epoch 00031: val_loss improved from 1.27253 to 1.26898, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2734 - accuracy: 0.4464 - val_loss: 1.2690 - val_accuracy: 0.4842
Epoch 32/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3288 - accuracy: 0.3594
Epoch 00032: val_loss improved from 1.26898 to 1.26423, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2839 - accuracy: 0.4573 - val_loss: 1.2642 - val_accuracy: 0.4822
Epoch 33/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3051 - accuracy: 0.3750
Epoch 00033: val_loss improved from 1.26423 to 1.26164, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2680 - accuracy: 0.4623 - val_loss: 1.2616 - val_accuracy: 0.4862
Epoch 34/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3129 - accuracy: 0.3906
Epoch 00034: val_loss improved from 1.26164 to 1.25732, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2766 - accuracy: 0.4593 - val_loss: 1.2573 - val_accuracy: 0.4881
Epoch 35/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2197 - accuracy: 0.4688
Epoch 00035: val_loss improved from 1.25732 to 1.25258, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2654 - accuracy: 0.4623 - val_loss: 1.2526 - val_accuracy: 0.4980
Epoch 36/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2918 - accuracy: 0.4062
Epoch 00036: val_loss improved from 1.25258 to 1.24935, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 90us/sample - loss: 1.2766 - accuracy: 0.4444 - val_loss: 1.2494 - val_accuracy: 0.4921
Epoch 37/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3450 - accuracy: 0.3594
Epoch 00037: val_loss improved from 1.24935 to 1.24743, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2686 - accuracy: 0.4593 - val_loss: 1.2474 - val_accuracy: 0.4980
Epoch 38/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2406 - accuracy: 0.5469
Epoch 00038: val_loss improved from 1.24743 to 1.24544, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2691 - accuracy: 0.4663 - val_loss: 1.2454 - val_accuracy: 0.4881
Epoch 39/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2420 - accuracy: 0.4844
Epoch 00039: val_loss did not improve from 1.24544
1008/1008 [==============================] - 0s 73us/sample - loss: 1.2663 - accuracy: 0.4583 - val_loss: 1.2473 - val_accuracy: 0.4901
Epoch 40/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2407 - accuracy: 0.4531
Epoch 00040: val_loss improved from 1.24544 to 1.24368, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2746 - accuracy: 0.4613 - val_loss: 1.2437 - val_accuracy: 0.4901
Epoch 41/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2157 - accuracy: 0.5625
Epoch 00041: val_loss improved from 1.24368 to 1.23945, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2568 - accuracy: 0.4841 - val_loss: 1.2394 - val_accuracy: 0.4941
Epoch 42/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2753 - accuracy: 0.4219
Epoch 00042: val_loss improved from 1.23945 to 1.23804, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 86us/sample - loss: 1.2571 - accuracy: 0.4782 - val_loss: 1.2380 - val_accuracy: 0.4941
Epoch 43/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2008 - accuracy: 0.5312
Epoch 00043: val_loss improved from 1.23804 to 1.23672, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2586 - accuracy: 0.4593 - val_loss: 1.2367 - val_accuracy: 0.5040
Epoch 44/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2448 - accuracy: 0.4844
Epoch 00044: val_loss did not improve from 1.23672
1008/1008 [==============================] - 0s 72us/sample - loss: 1.2600 - accuracy: 0.4782 - val_loss: 1.2413 - val_accuracy: 0.4980
Epoch 45/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3042 - accuracy: 0.4219
Epoch 00045: val_loss did not improve from 1.23672
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2657 - accuracy: 0.4722 - val_loss: 1.2425 - val_accuracy: 0.4960
Epoch 46/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2643 - accuracy: 0.4375
Epoch 00046: val_loss improved from 1.23672 to 1.23498, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2646 - accuracy: 0.4683 - val_loss: 1.2350 - val_accuracy: 0.5099
Epoch 47/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2778 - accuracy: 0.4531
Epoch 00047: val_loss improved from 1.23498 to 1.23011, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2568 - accuracy: 0.4821 - val_loss: 1.2301 - val_accuracy: 0.5059
Epoch 48/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.3003 - accuracy: 0.4219
Epoch 00048: val_loss improved from 1.23011 to 1.23009, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2571 - accuracy: 0.4851 - val_loss: 1.2301 - val_accuracy: 0.5099
Epoch 49/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2872 - accuracy: 0.3906
Epoch 00049: val_loss improved from 1.23009 to 1.22779, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 86us/sample - loss: 1.2379 - accuracy: 0.5020 - val_loss: 1.2278 - val_accuracy: 0.5099
Epoch 50/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1890 - accuracy: 0.5781
Epoch 00050: val_loss improved from 1.22779 to 1.22671, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2499 - accuracy: 0.4881 - val_loss: 1.2267 - val_accuracy: 0.5119
Epoch 51/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2763 - accuracy: 0.4531
Epoch 00051: val_loss improved from 1.22671 to 1.22443, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 87us/sample - loss: 1.2431 - accuracy: 0.4921 - val_loss: 1.2244 - val_accuracy: 0.5119
Epoch 52/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2762 - accuracy: 0.4531
Epoch 00052: val_loss improved from 1.22443 to 1.22438, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2617 - accuracy: 0.4534 - val_loss: 1.2244 - val_accuracy: 0.5158
Epoch 53/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2167 - accuracy: 0.5000
Epoch 00053: val_loss improved from 1.22438 to 1.22283, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2525 - accuracy: 0.4762 - val_loss: 1.2228 - val_accuracy: 0.5158
Epoch 54/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2525 - accuracy: 0.5000
Epoch 00054: val_loss improved from 1.22283 to 1.22049, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 87us/sample - loss: 1.2442 - accuracy: 0.4990 - val_loss: 1.2205 - val_accuracy: 0.5178
Epoch 55/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1885 - accuracy: 0.5469
Epoch 00055: val_loss did not improve from 1.22049
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2453 - accuracy: 0.4911 - val_loss: 1.2211 - val_accuracy: 0.5158
Epoch 56/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2536 - accuracy: 0.4688
Epoch 00056: val_loss improved from 1.22049 to 1.22022, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2447 - accuracy: 0.4980 - val_loss: 1.2202 - val_accuracy: 0.5237
Epoch 57/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2338 - accuracy: 0.5156
Epoch 00057: val_loss did not improve from 1.22022
1008/1008 [==============================] - 0s 74us/sample - loss: 1.2448 - accuracy: 0.4911 - val_loss: 1.2203 - val_accuracy: 0.5336
Epoch 58/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2071 - accuracy: 0.5625
Epoch 00058: val_loss did not improve from 1.22022
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2312 - accuracy: 0.5069 - val_loss: 1.2236 - val_accuracy: 0.5257
Epoch 59/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2319 - accuracy: 0.5312
Epoch 00059: val_loss did not improve from 1.22022
1008/1008 [==============================] - 0s 71us/sample - loss: 1.2435 - accuracy: 0.4960 - val_loss: 1.2236 - val_accuracy: 0.5336
Epoch 60/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1918 - accuracy: 0.5625
Epoch 00060: val_loss did not improve from 1.22022
1008/1008 [==============================] - 0s 70us/sample - loss: 1.2300 - accuracy: 0.5119 - val_loss: 1.2214 - val_accuracy: 0.5415
Epoch 61/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2701 - accuracy: 0.5000
Epoch 00061: val_loss improved from 1.22022 to 1.22009, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.2278 - accuracy: 0.5208 - val_loss: 1.2201 - val_accuracy: 0.5336
Epoch 62/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2193 - accuracy: 0.5625
Epoch 00062: val_loss improved from 1.22009 to 1.21450, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.2408 - accuracy: 0.5010 - val_loss: 1.2145 - val_accuracy: 0.5435
Epoch 63/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1666 - accuracy: 0.6094 896/1008 [=========================>....] - ETA: 0s - loss: 1.2221 - accuracy: 0.5145
Epoch 00063: val_loss improved from 1.21450 to 1.21350, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 94us/sample - loss: 1.2219 - accuracy: 0.5139 - val_loss: 1.2135 - val_accuracy: 0.5534
Epoch 64/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2232 - accuracy: 0.4844
Epoch 00064: val_loss improved from 1.21350 to 1.21124, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2110 - accuracy: 0.5387 - val_loss: 1.2112 - val_accuracy: 0.5573
Epoch 65/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2437 - accuracy: 0.5000
Epoch 00065: val_loss improved from 1.21124 to 1.20684, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.2322 - accuracy: 0.5099 - val_loss: 1.2068 - val_accuracy: 0.5534
Epoch 66/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2371 - accuracy: 0.5156
Epoch 00066: val_loss improved from 1.20684 to 1.20502, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 91us/sample - loss: 1.2171 - accuracy: 0.5298 - val_loss: 1.2050 - val_accuracy: 0.5494
Epoch 67/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2550 - accuracy: 0.5000 960/1008 [===========================>..] - ETA: 0s - loss: 1.2218 - accuracy: 0.5240
Epoch 00067: val_loss did not improve from 1.20502
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2191 - accuracy: 0.5278 - val_loss: 1.2052 - val_accuracy: 0.5474
Epoch 68/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2669 - accuracy: 0.4688 960/1008 [===========================>..] - ETA: 0s - loss: 1.2174 - accuracy: 0.5302
Epoch 00068: val_loss did not improve from 1.20502
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2155 - accuracy: 0.5357 - val_loss: 1.2063 - val_accuracy: 0.5494
Epoch 69/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2726 - accuracy: 0.4688 960/1008 [===========================>..] - ETA: 0s - loss: 1.2248 - accuracy: 0.5167
Epoch 00069: val_loss did not improve from 1.20502
1008/1008 [==============================] - 0s 80us/sample - loss: 1.2233 - accuracy: 0.5228 - val_loss: 1.2058 - val_accuracy: 0.5455
Epoch 70/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1827 - accuracy: 0.5781
Epoch 00070: val_loss improved from 1.20502 to 1.20286, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2105 - accuracy: 0.5387 - val_loss: 1.2029 - val_accuracy: 0.5494
Epoch 71/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2130 - accuracy: 0.5156
Epoch 00071: val_loss did not improve from 1.20286
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1973 - accuracy: 0.5575 - val_loss: 1.2032 - val_accuracy: 0.5593
Epoch 72/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1885 - accuracy: 0.6250
Epoch 00072: val_loss did not improve from 1.20286
1008/1008 [==============================] - 0s 72us/sample - loss: 1.2098 - accuracy: 0.5427 - val_loss: 1.2064 - val_accuracy: 0.5435
Epoch 73/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2263 - accuracy: 0.5312
Epoch 00073: val_loss improved from 1.20286 to 1.20188, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.2042 - accuracy: 0.5437 - val_loss: 1.2019 - val_accuracy: 0.5553
Epoch 74/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2538 - accuracy: 0.4844
Epoch 00074: val_loss improved from 1.20188 to 1.19919, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.2024 - accuracy: 0.5427 - val_loss: 1.1992 - val_accuracy: 0.5534
Epoch 75/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1695 - accuracy: 0.5312
Epoch 00075: val_loss improved from 1.19919 to 1.19712, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1996 - accuracy: 0.5337 - val_loss: 1.1971 - val_accuracy: 0.5573
Epoch 76/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2210 - accuracy: 0.5312
Epoch 00076: val_loss did not improve from 1.19712
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1960 - accuracy: 0.5546 - val_loss: 1.1978 - val_accuracy: 0.5534
Epoch 77/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1922 - accuracy: 0.5781
Epoch 00077: val_loss improved from 1.19712 to 1.19484, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1981 - accuracy: 0.5575 - val_loss: 1.1948 - val_accuracy: 0.5573
Epoch 78/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2010 - accuracy: 0.5312
Epoch 00078: val_loss did not improve from 1.19484
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1972 - accuracy: 0.5466 - val_loss: 1.1979 - val_accuracy: 0.5553
Epoch 79/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2393 - accuracy: 0.4844
Epoch 00079: val_loss did not improve from 1.19484
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1809 - accuracy: 0.5615 - val_loss: 1.2048 - val_accuracy: 0.5593
Epoch 80/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1724 - accuracy: 0.5312
Epoch 00080: val_loss did not improve from 1.19484
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1869 - accuracy: 0.5625 - val_loss: 1.2018 - val_accuracy: 0.5593
Epoch 81/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1521 - accuracy: 0.5938
Epoch 00081: val_loss did not improve from 1.19484
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1873 - accuracy: 0.5476 - val_loss: 1.2071 - val_accuracy: 0.5494
Epoch 82/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1774 - accuracy: 0.5938 960/1008 [===========================>..] - ETA: 0s - loss: 1.1865 - accuracy: 0.5625
Epoch 00082: val_loss did not improve from 1.19484
1008/1008 [==============================] - 0s 79us/sample - loss: 1.1852 - accuracy: 0.5645 - val_loss: 1.2068 - val_accuracy: 0.5455
Epoch 83/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1382 - accuracy: 0.5781
Epoch 00083: val_loss did not improve from 1.19484
1008/1008 [==============================] - 0s 77us/sample - loss: 1.1701 - accuracy: 0.5843 - val_loss: 1.2052 - val_accuracy: 0.5455
Epoch 84/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1912 - accuracy: 0.5000 960/1008 [===========================>..] - ETA: 0s - loss: 1.1836 - accuracy: 0.5698
Epoch 00084: val_loss did not improve from 1.19484
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1892 - accuracy: 0.5625 - val_loss: 1.1966 - val_accuracy: 0.5534
Epoch 85/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2069 - accuracy: 0.5625 960/1008 [===========================>..] - ETA: 0s - loss: 1.1984 - accuracy: 0.5542
Epoch 00085: val_loss improved from 1.19484 to 1.19299, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 98us/sample - loss: 1.1966 - accuracy: 0.5565 - val_loss: 1.1930 - val_accuracy: 0.5494
Epoch 86/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2134 - accuracy: 0.5156 960/1008 [===========================>..] - ETA: 0s - loss: 1.1672 - accuracy: 0.5885
Epoch 00086: val_loss improved from 1.19299 to 1.18992, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 94us/sample - loss: 1.1713 - accuracy: 0.5833 - val_loss: 1.1899 - val_accuracy: 0.5573
Epoch 87/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2229 - accuracy: 0.5156
Epoch 00087: val_loss did not improve from 1.18992
1008/1008 [==============================] - 0s 76us/sample - loss: 1.1883 - accuracy: 0.5615 - val_loss: 1.1928 - val_accuracy: 0.5652
Epoch 88/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1689 - accuracy: 0.5625
Epoch 00088: val_loss did not improve from 1.18992
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1702 - accuracy: 0.5764 - val_loss: 1.1918 - val_accuracy: 0.5652
Epoch 89/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2138 - accuracy: 0.5312 896/1008 [=========================>....] - ETA: 0s - loss: 1.1704 - accuracy: 0.5982
Epoch 00089: val_loss did not improve from 1.18992
1008/1008 [==============================] - 0s 94us/sample - loss: 1.1778 - accuracy: 0.5853 - val_loss: 1.1922 - val_accuracy: 0.5514
Epoch 90/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1599 - accuracy: 0.5781
Epoch 00090: val_loss did not improve from 1.18992
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1790 - accuracy: 0.5665 - val_loss: 1.1961 - val_accuracy: 0.5474
Epoch 91/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2571 - accuracy: 0.4688
Epoch 00091: val_loss did not improve from 1.18992
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1696 - accuracy: 0.5635 - val_loss: 1.1923 - val_accuracy: 0.5711
Epoch 92/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1519 - accuracy: 0.5938
Epoch 00092: val_loss did not improve from 1.18992
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1673 - accuracy: 0.5942 - val_loss: 1.1927 - val_accuracy: 0.5593
Epoch 93/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1454 - accuracy: 0.5781
Epoch 00093: val_loss did not improve from 1.18992
1008/1008 [==============================] - 0s 69us/sample - loss: 1.1532 - accuracy: 0.5913 - val_loss: 1.1951 - val_accuracy: 0.5672
Epoch 94/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1475 - accuracy: 0.6094
Epoch 00094: val_loss improved from 1.18992 to 1.18858, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1625 - accuracy: 0.5962 - val_loss: 1.1886 - val_accuracy: 0.5573
Epoch 95/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1568 - accuracy: 0.5625
Epoch 00095: val_loss improved from 1.18858 to 1.18607, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1844 - accuracy: 0.5625 - val_loss: 1.1861 - val_accuracy: 0.5593
Epoch 96/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1949 - accuracy: 0.5625
Epoch 00096: val_loss improved from 1.18607 to 1.18375, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1480 - accuracy: 0.6190 - val_loss: 1.1837 - val_accuracy: 0.5593
Epoch 97/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1549 - accuracy: 0.5781
Epoch 00097: val_loss did not improve from 1.18375
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1632 - accuracy: 0.5823 - val_loss: 1.1884 - val_accuracy: 0.5573
Epoch 98/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1412 - accuracy: 0.6406
Epoch 00098: val_loss did not improve from 1.18375
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1605 - accuracy: 0.5843 - val_loss: 1.1905 - val_accuracy: 0.5652
Epoch 99/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1738 - accuracy: 0.5469
Epoch 00099: val_loss did not improve from 1.18375
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1643 - accuracy: 0.5893 - val_loss: 1.1862 - val_accuracy: 0.5534
Epoch 100/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1431 - accuracy: 0.6094
Epoch 00100: val_loss did not improve from 1.18375
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1681 - accuracy: 0.5843 - val_loss: 1.1858 - val_accuracy: 0.5514
Epoch 101/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2490 - accuracy: 0.4531
Epoch 00101: val_loss improved from 1.18375 to 1.18193, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1633 - accuracy: 0.5942 - val_loss: 1.1819 - val_accuracy: 0.5632
Epoch 102/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1355 - accuracy: 0.6094
Epoch 00102: val_loss did not improve from 1.18193
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1581 - accuracy: 0.5942 - val_loss: 1.1846 - val_accuracy: 0.5593
Epoch 103/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2019 - accuracy: 0.5469
Epoch 00103: val_loss did not improve from 1.18193
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1441 - accuracy: 0.6101 - val_loss: 1.1840 - val_accuracy: 0.5613
Epoch 104/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1490 - accuracy: 0.6250
Epoch 00104: val_loss did not improve from 1.18193
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1333 - accuracy: 0.6290 - val_loss: 1.1833 - val_accuracy: 0.5632
Epoch 105/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1659 - accuracy: 0.5625
Epoch 00105: val_loss did not improve from 1.18193
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1431 - accuracy: 0.6062 - val_loss: 1.1841 - val_accuracy: 0.5553
Epoch 106/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1432 - accuracy: 0.6094
Epoch 00106: val_loss did not improve from 1.18193
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1418 - accuracy: 0.6141 - val_loss: 1.1843 - val_accuracy: 0.5553
Epoch 107/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1391 - accuracy: 0.6250
Epoch 00107: val_loss improved from 1.18193 to 1.18190, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 85us/sample - loss: 1.1321 - accuracy: 0.6161 - val_loss: 1.1819 - val_accuracy: 0.5514
Epoch 108/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1234 - accuracy: 0.6094
Epoch 00108: val_loss improved from 1.18190 to 1.17804, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1385 - accuracy: 0.6161 - val_loss: 1.1780 - val_accuracy: 0.5613
Epoch 109/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1095 - accuracy: 0.6250
Epoch 00109: val_loss improved from 1.17804 to 1.17685, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1242 - accuracy: 0.6220 - val_loss: 1.1769 - val_accuracy: 0.5652
Epoch 110/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1310 - accuracy: 0.6250
Epoch 00110: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1250 - accuracy: 0.6329 - val_loss: 1.1829 - val_accuracy: 0.5514
Epoch 111/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0773 - accuracy: 0.7188
Epoch 00111: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 69us/sample - loss: 1.1331 - accuracy: 0.6369 - val_loss: 1.1791 - val_accuracy: 0.5632
Epoch 112/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1574 - accuracy: 0.6094
Epoch 00112: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1229 - accuracy: 0.6399 - val_loss: 1.1818 - val_accuracy: 0.5553
Epoch 113/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1140 - accuracy: 0.6719
Epoch 00113: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 75us/sample - loss: 1.1249 - accuracy: 0.6210 - val_loss: 1.1893 - val_accuracy: 0.5613
Epoch 114/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1784 - accuracy: 0.5781
Epoch 00114: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1327 - accuracy: 0.6230 - val_loss: 1.1955 - val_accuracy: 0.5474
Epoch 115/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0910 - accuracy: 0.6875
Epoch 00115: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 71us/sample - loss: 1.1208 - accuracy: 0.6369 - val_loss: 1.1838 - val_accuracy: 0.5672
Epoch 116/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0736 - accuracy: 0.7188
Epoch 00116: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1069 - accuracy: 0.6458 - val_loss: 1.1840 - val_accuracy: 0.5613
Epoch 117/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1542 - accuracy: 0.5938
Epoch 00117: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 73us/sample - loss: 1.1152 - accuracy: 0.6399 - val_loss: 1.1814 - val_accuracy: 0.5632
Epoch 118/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1342 - accuracy: 0.6094
Epoch 00118: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1224 - accuracy: 0.6270 - val_loss: 1.1818 - val_accuracy: 0.5553
Epoch 119/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1234 - accuracy: 0.6562 960/1008 [===========================>..] - ETA: 0s - loss: 1.1194 - accuracy: 0.6281
Epoch 00119: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 81us/sample - loss: 1.1193 - accuracy: 0.6290 - val_loss: 1.1773 - val_accuracy: 0.5652
Epoch 120/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1269 - accuracy: 0.6250 960/1008 [===========================>..] - ETA: 0s - loss: 1.1176 - accuracy: 0.6417
Epoch 00120: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 83us/sample - loss: 1.1157 - accuracy: 0.6429 - val_loss: 1.1824 - val_accuracy: 0.5652
Epoch 121/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.2013 - accuracy: 0.5156 960/1008 [===========================>..] - ETA: 0s - loss: 1.1170 - accuracy: 0.6375
Epoch 00121: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 82us/sample - loss: 1.1188 - accuracy: 0.6359 - val_loss: 1.1854 - val_accuracy: 0.5553
Epoch 122/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0214 - accuracy: 0.7656
Epoch 00122: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 76us/sample - loss: 1.1198 - accuracy: 0.6310 - val_loss: 1.1820 - val_accuracy: 0.5593
Epoch 123/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0853 - accuracy: 0.6562
Epoch 00123: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 69us/sample - loss: 1.1179 - accuracy: 0.6240 - val_loss: 1.1856 - val_accuracy: 0.5573
Epoch 124/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1737 - accuracy: 0.5469
Epoch 00124: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.1125 - accuracy: 0.6379 - val_loss: 1.1785 - val_accuracy: 0.5652
Epoch 125/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0966 - accuracy: 0.6562
Epoch 00125: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 78us/sample - loss: 1.1049 - accuracy: 0.6498 - val_loss: 1.1914 - val_accuracy: 0.5534
Epoch 126/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0934 - accuracy: 0.6562 960/1008 [===========================>..] - ETA: 0s - loss: 1.1039 - accuracy: 0.6490
Epoch 00126: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 84us/sample - loss: 1.1033 - accuracy: 0.6488 - val_loss: 1.1855 - val_accuracy: 0.5593
Epoch 127/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1307 - accuracy: 0.6250 704/1008 [===================>..........] - ETA: 0s - loss: 1.0952 - accuracy: 0.6591
Epoch 00127: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 98us/sample - loss: 1.0968 - accuracy: 0.6587 - val_loss: 1.1851 - val_accuracy: 0.5593
Epoch 128/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1639 - accuracy: 0.5938 960/1008 [===========================>..] - ETA: 0s - loss: 1.1098 - accuracy: 0.6385
Epoch 00128: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 80us/sample - loss: 1.1052 - accuracy: 0.6429 - val_loss: 1.1789 - val_accuracy: 0.5652
Epoch 129/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0228 - accuracy: 0.7500
Epoch 00129: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0977 - accuracy: 0.6498 - val_loss: 1.1966 - val_accuracy: 0.5553
Epoch 130/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0863 - accuracy: 0.6719
Epoch 00130: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0983 - accuracy: 0.6538 - val_loss: 1.1897 - val_accuracy: 0.5435
Epoch 131/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1609 - accuracy: 0.6094
Epoch 00131: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0926 - accuracy: 0.6597 - val_loss: 1.2021 - val_accuracy: 0.5415
Epoch 132/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1287 - accuracy: 0.5781
Epoch 00132: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0932 - accuracy: 0.6577 - val_loss: 1.1858 - val_accuracy: 0.5534
Epoch 133/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1214 - accuracy: 0.6406
Epoch 00133: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0968 - accuracy: 0.6558 - val_loss: 1.1904 - val_accuracy: 0.5474
Epoch 134/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1114 - accuracy: 0.6719
Epoch 00134: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 72us/sample - loss: 1.1011 - accuracy: 0.6518 - val_loss: 1.1824 - val_accuracy: 0.5613
Epoch 135/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0923 - accuracy: 0.6875
Epoch 00135: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0943 - accuracy: 0.6647 - val_loss: 1.1786 - val_accuracy: 0.5573
Epoch 136/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0827 - accuracy: 0.6562
Epoch 00136: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0914 - accuracy: 0.6667 - val_loss: 1.1776 - val_accuracy: 0.5514
Epoch 137/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0453 - accuracy: 0.6719
Epoch 00137: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0854 - accuracy: 0.6627 - val_loss: 1.1786 - val_accuracy: 0.5672
Epoch 138/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0352 - accuracy: 0.7031
Epoch 00138: val_loss did not improve from 1.17685
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0773 - accuracy: 0.6726 - val_loss: 1.1823 - val_accuracy: 0.5514
Epoch 139/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0831 - accuracy: 0.6562
Epoch 00139: val_loss improved from 1.17685 to 1.17054, saving model to saved_models/TfidfVectorizer_bestloss
1008/1008 [==============================] - 0s 82us/sample - loss: 1.0850 - accuracy: 0.6736 - val_loss: 1.1705 - val_accuracy: 0.5632
Epoch 140/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0764 - accuracy: 0.6562 960/1008 [===========================>..] - ETA: 0s - loss: 1.0864 - accuracy: 0.6521
Epoch 00140: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 80us/sample - loss: 1.0876 - accuracy: 0.6508 - val_loss: 1.1735 - val_accuracy: 0.5613
Epoch 141/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0663 - accuracy: 0.6719
Epoch 00141: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0876 - accuracy: 0.6687 - val_loss: 1.1818 - val_accuracy: 0.5593
Epoch 142/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0189 - accuracy: 0.7188
Epoch 00142: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0760 - accuracy: 0.6696 - val_loss: 1.1766 - val_accuracy: 0.5534
Epoch 143/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0990 - accuracy: 0.6250
Epoch 00143: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0871 - accuracy: 0.6617 - val_loss: 1.1728 - val_accuracy: 0.5613
Epoch 144/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1180 - accuracy: 0.6250
Epoch 00144: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0661 - accuracy: 0.6796 - val_loss: 1.1811 - val_accuracy: 0.5514
Epoch 145/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0853 - accuracy: 0.6562
Epoch 00145: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0625 - accuracy: 0.6885 - val_loss: 1.1766 - val_accuracy: 0.5553
Epoch 146/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1844 - accuracy: 0.5781
Epoch 00146: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0846 - accuracy: 0.6726 - val_loss: 1.1770 - val_accuracy: 0.5573
Epoch 147/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1256 - accuracy: 0.5781
Epoch 00147: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0752 - accuracy: 0.6647 - val_loss: 1.1759 - val_accuracy: 0.5474
Epoch 148/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0739 - accuracy: 0.6875
Epoch 00148: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0940 - accuracy: 0.6617 - val_loss: 1.1706 - val_accuracy: 0.5613
Epoch 149/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0803 - accuracy: 0.6719
Epoch 00149: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0695 - accuracy: 0.6825 - val_loss: 1.1771 - val_accuracy: 0.5573
Epoch 150/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1153 - accuracy: 0.5938
Epoch 00150: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0678 - accuracy: 0.6865 - val_loss: 1.1745 - val_accuracy: 0.5514
Epoch 151/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0725 - accuracy: 0.6719
Epoch 00151: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0648 - accuracy: 0.6806 - val_loss: 1.1808 - val_accuracy: 0.5474
Epoch 152/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0817 - accuracy: 0.6406
Epoch 00152: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0516 - accuracy: 0.6974 - val_loss: 1.1763 - val_accuracy: 0.5593
Epoch 153/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0695 - accuracy: 0.7031
Epoch 00153: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0737 - accuracy: 0.6815 - val_loss: 1.1747 - val_accuracy: 0.5731
Epoch 154/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0510 - accuracy: 0.6875
Epoch 00154: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0714 - accuracy: 0.6786 - val_loss: 1.1877 - val_accuracy: 0.5553
Epoch 155/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0599 - accuracy: 0.6719
Epoch 00155: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0546 - accuracy: 0.6984 - val_loss: 1.1755 - val_accuracy: 0.5593
Epoch 156/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0831 - accuracy: 0.6719
Epoch 00156: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0617 - accuracy: 0.6915 - val_loss: 1.1741 - val_accuracy: 0.5593
Epoch 157/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0749 - accuracy: 0.6562
Epoch 00157: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0711 - accuracy: 0.6835 - val_loss: 1.1797 - val_accuracy: 0.5514
Epoch 158/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0213 - accuracy: 0.7656
Epoch 00158: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0621 - accuracy: 0.6895 - val_loss: 1.1744 - val_accuracy: 0.5534
Epoch 159/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0947 - accuracy: 0.6719
Epoch 00159: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0599 - accuracy: 0.6954 - val_loss: 1.1778 - val_accuracy: 0.5632
Epoch 160/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0870 - accuracy: 0.6719
Epoch 00160: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0616 - accuracy: 0.6825 - val_loss: 1.1753 - val_accuracy: 0.5573
Epoch 161/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0117 - accuracy: 0.7500
Epoch 00161: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0480 - accuracy: 0.6984 - val_loss: 1.1768 - val_accuracy: 0.5593
Epoch 162/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1605 - accuracy: 0.5781
Epoch 00162: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0592 - accuracy: 0.6855 - val_loss: 1.1903 - val_accuracy: 0.5435
Epoch 163/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0373 - accuracy: 0.7188
Epoch 00163: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0594 - accuracy: 0.6915 - val_loss: 1.1784 - val_accuracy: 0.5534
Epoch 164/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0701 - accuracy: 0.6719
Epoch 00164: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0466 - accuracy: 0.7034 - val_loss: 1.1769 - val_accuracy: 0.5534
Epoch 165/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0582 - accuracy: 0.6719
Epoch 00165: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0523 - accuracy: 0.7044 - val_loss: 1.1827 - val_accuracy: 0.5494
Epoch 166/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9595 - accuracy: 0.7969
Epoch 00166: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0470 - accuracy: 0.7123 - val_loss: 1.1854 - val_accuracy: 0.5435
Epoch 167/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0614 - accuracy: 0.6719
Epoch 00167: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0605 - accuracy: 0.6885 - val_loss: 1.1788 - val_accuracy: 0.5435
Epoch 168/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0453 - accuracy: 0.7188
Epoch 00168: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0456 - accuracy: 0.7103 - val_loss: 1.1767 - val_accuracy: 0.5514
Epoch 169/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0168 - accuracy: 0.7500
Epoch 00169: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0492 - accuracy: 0.7063 - val_loss: 1.1764 - val_accuracy: 0.5514
Epoch 170/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0736 - accuracy: 0.6719
Epoch 00170: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0485 - accuracy: 0.7034 - val_loss: 1.1721 - val_accuracy: 0.5652
Epoch 171/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9568 - accuracy: 0.8125
Epoch 00171: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 69us/sample - loss: 1.0367 - accuracy: 0.7123 - val_loss: 1.1785 - val_accuracy: 0.5593
Epoch 172/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0780 - accuracy: 0.6875
Epoch 00172: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 69us/sample - loss: 1.0479 - accuracy: 0.7083 - val_loss: 1.1844 - val_accuracy: 0.5514
Epoch 173/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0855 - accuracy: 0.6250
Epoch 00173: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0508 - accuracy: 0.6964 - val_loss: 1.1835 - val_accuracy: 0.5494
Epoch 174/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.1193 - accuracy: 0.6406
Epoch 00174: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0378 - accuracy: 0.7133 - val_loss: 1.1839 - val_accuracy: 0.5514
Epoch 175/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0003 - accuracy: 0.7344
Epoch 00175: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0474 - accuracy: 0.6974 - val_loss: 1.1853 - val_accuracy: 0.5514
Epoch 176/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9986 - accuracy: 0.7500
Epoch 00176: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0365 - accuracy: 0.7133 - val_loss: 1.1822 - val_accuracy: 0.5494
Epoch 177/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9718 - accuracy: 0.7812
Epoch 00177: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0404 - accuracy: 0.7054 - val_loss: 1.1816 - val_accuracy: 0.5375
Epoch 178/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0360 - accuracy: 0.7188
Epoch 00178: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0419 - accuracy: 0.7123 - val_loss: 1.1881 - val_accuracy: 0.5455
Epoch 179/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0462 - accuracy: 0.7188
Epoch 00179: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0285 - accuracy: 0.7222 - val_loss: 1.1792 - val_accuracy: 0.5435
Epoch 180/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0618 - accuracy: 0.6875
Epoch 00180: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0388 - accuracy: 0.7123 - val_loss: 1.1873 - val_accuracy: 0.5395
Epoch 181/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0381 - accuracy: 0.7188
Epoch 00181: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0287 - accuracy: 0.7192 - val_loss: 1.1803 - val_accuracy: 0.5494
Epoch 182/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0215 - accuracy: 0.7344
Epoch 00182: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0373 - accuracy: 0.7014 - val_loss: 1.1818 - val_accuracy: 0.5435
Epoch 183/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0861 - accuracy: 0.6562
Epoch 00183: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0215 - accuracy: 0.7252 - val_loss: 1.1827 - val_accuracy: 0.5455
Epoch 184/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0503 - accuracy: 0.7031
Epoch 00184: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0424 - accuracy: 0.7014 - val_loss: 1.1838 - val_accuracy: 0.5474
Epoch 185/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0114 - accuracy: 0.7188
Epoch 00185: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0319 - accuracy: 0.7073 - val_loss: 1.1848 - val_accuracy: 0.5375
Epoch 186/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0630 - accuracy: 0.7031
Epoch 00186: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0468 - accuracy: 0.7063 - val_loss: 1.1837 - val_accuracy: 0.5395
Epoch 187/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0292 - accuracy: 0.7188
Epoch 00187: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 68us/sample - loss: 1.0266 - accuracy: 0.7173 - val_loss: 1.1822 - val_accuracy: 0.5395
Epoch 188/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0368 - accuracy: 0.7344
Epoch 00188: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0427 - accuracy: 0.7024 - val_loss: 1.1908 - val_accuracy: 0.5356
Epoch 189/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0537 - accuracy: 0.6875
Epoch 00189: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0268 - accuracy: 0.7192 - val_loss: 1.1812 - val_accuracy: 0.5474
Epoch 190/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9982 - accuracy: 0.7656
Epoch 00190: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0246 - accuracy: 0.7272 - val_loss: 1.1813 - val_accuracy: 0.5494
Epoch 191/200
  64/1008 [>.............................] - ETA: 0s - loss: 0.9912 - accuracy: 0.7500
Epoch 00191: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0232 - accuracy: 0.7212 - val_loss: 1.1765 - val_accuracy: 0.5514
Epoch 192/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0620 - accuracy: 0.6875
Epoch 00192: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0380 - accuracy: 0.7123 - val_loss: 1.1745 - val_accuracy: 0.5494
Epoch 193/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0024 - accuracy: 0.7500
Epoch 00193: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0157 - accuracy: 0.7302 - val_loss: 1.1847 - val_accuracy: 0.5435
Epoch 194/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0813 - accuracy: 0.6562
Epoch 00194: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0309 - accuracy: 0.7163 - val_loss: 1.1783 - val_accuracy: 0.5415
Epoch 195/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0082 - accuracy: 0.7500
Epoch 00195: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0191 - accuracy: 0.7272 - val_loss: 1.1810 - val_accuracy: 0.5415
Epoch 196/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0782 - accuracy: 0.6562
Epoch 00196: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 79us/sample - loss: 1.0165 - accuracy: 0.7431 - val_loss: 1.1779 - val_accuracy: 0.5474
Epoch 197/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0035 - accuracy: 0.7344
Epoch 00197: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 70us/sample - loss: 1.0171 - accuracy: 0.7282 - val_loss: 1.1813 - val_accuracy: 0.5415
Epoch 198/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0158 - accuracy: 0.7344
Epoch 00198: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 72us/sample - loss: 1.0174 - accuracy: 0.7262 - val_loss: 1.1821 - val_accuracy: 0.5474
Epoch 199/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0443 - accuracy: 0.6875
Epoch 00199: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 71us/sample - loss: 1.0089 - accuracy: 0.7411 - val_loss: 1.1759 - val_accuracy: 0.5553
Epoch 200/200
  64/1008 [>.............................] - ETA: 0s - loss: 1.0433 - accuracy: 0.7188
Epoch 00200: val_loss did not improve from 1.17054
1008/1008 [==============================] - 0s 68us/sample - loss: 1.0141 - accuracy: 0.7321 - val_loss: 1.1744 - val_accuracy: 0.5553

Results of vectorizer TfidfVectorizer using a dnn:
acc   = 0.5632411067193676
macro = (0.3097753007784855, 0.3771003999682745, 0.33147421409616534, None)

The best model config with is:
	vectorizer = CountVectorizer
	classifier = dnn
	results: accuracy=0.575098814229249 - macro=(0.44553147625997136, 0.399144716196917, 0.3730983563841493, None)
